{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "from distance_matching_functional import DistanceMatching\n",
    "from distance_matching_lowrank import DistanceMatching as DMR_LR\n",
    "import functions\n",
    "import utils\n",
    "\n",
    "sys.path.append(\"../baselines/\")\n",
    "from baselines import baselines \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "remake_delta_Z = False\n",
    "\n",
    "refit_mixture = False\n",
    "refit_vc      = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "X_train = np.load(\"X_train.npy\")\n",
    "Y_train = np.load(\"Y_train.npy\")\n",
    "Z_train = np.load(\"Z_train.npy\")\n",
    "X_test  = np.load(\"X_test.npy\")\n",
    "Y_test  = np.load(\"Y_test.npy\")\n",
    "Z_test  = np.load(\"Z_test.npy\")\n",
    "delta_Z = np.load(\"delta_Z.npy\")\n",
    "K = Z_train.shape[1]\n",
    "print(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.decomposition import PCA\n",
    "#pca = PCA(n_components=5)\n",
    "#X_train = pca.fit_transform(X_train)\n",
    "#X_test  = pca.transform(X_test)\n",
    "X_train = X_train[:, :5]\n",
    "X_test  = X_test[:, :5]\n",
    "\n",
    "X_train = np.hstack((X_train, np.expand_dims(np.ones_like(X_train[:, 0]), 1)))\n",
    "X_test  = np.hstack((X_test,  np.expand_dims(np.ones_like(X_test[:, 0]), 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reducing Z size... Finished.\n",
      "(2135, 2)\n",
      "(712, 2)\n"
     ]
    }
   ],
   "source": [
    "desired_Z_features = 2\n",
    "if Z_train.shape[1] > desired_Z_features:\n",
    "    print(\"Reducing Z size...\", end=' ')\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA(n_components=desired_Z_features)\n",
    "    Z_train = pca.fit_transform(Z_train)\n",
    "    Z_test  = pca.transform(Z_test)\n",
    "    print(\"Finished.\")\n",
    "K = Z_train.shape[1]\n",
    "\n",
    "dZ = [\n",
    "    lambda x,y: functions.safe_wrapper(x, y, functions.abs_diff),\n",
    "    lambda x,y: functions.safe_wrapper(x, y, functions.abs_diff)\n",
    "]\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "Z_train, norms = normalize(Z_train, norm='l1', axis=0, return_norm=True)\n",
    "Z_test /= norms\n",
    "print(Z_train.shape)\n",
    "print(Z_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-9.301139779866088e+17\n",
      "-0.00017189116866700438\n",
      "-3.169274143144385e-05\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression baseline\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from sklearn.linear_model import LinearRegression as LR\n",
    "lr = LR()\n",
    "lr_coef = []\n",
    "for i in range(Y_train.shape[1]):\n",
    "    lr.fit(X_train, Y_train[:, i])\n",
    "    print(lr.score(X_test, Y_test[:, i]))\n",
    "    lr_coef.append(lr.coef_)\n",
    "lr_coef = np.array(lr_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.00020131379799217985\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "en = ElasticNet(alpha=1e-3, l1_ratio=0.1, fit_intercept=False, normalize=True)\n",
    "en.fit(X_train, Y_train)\n",
    "print(en.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "remake_delta_U_test_train = False\n",
    "N_train = len(X_train)\n",
    "\n",
    "if remake_delta_U_test_train:\n",
    "    N_test = len(X_test)\n",
    "    N_train = len(X_train)\n",
    "    delta_U_test_train = np.zeros((N_test, N_train, K))\n",
    "    print(\"Calculating Delta_U Test/Train\")\n",
    "    for i in range(N_test):\n",
    "        print(\"{} / {}\".format(i, N_test), end='\\r')\n",
    "        for j in range(N_train):\n",
    "            delta_U_test_train[i, j, :] = np.array([dZ[k](Z_train[j, k], Z_test[i, k]) for k in range(K)])\n",
    "    np.save(\"delta_U_test_train.npy\", delta_U_test_train)\n",
    "else:\n",
    "    delta_U_test_train = np.load(\"delta_U_test_train.npy\")\n",
    "\n",
    "def calc_test_err(beta, X, Y, delta_U_test_train, n_neighbors,\n",
    "                  phi_u=None, mse=True, mae=False):\n",
    "    if phi_u is None:\n",
    "        phi_u = np.ones_like(U_train[0], dtype='float64')\n",
    "\n",
    "    K = len(delta_U_test_train[0, 0])\n",
    "    N_train = delta_U_test_train.shape[1]\n",
    "    err1 = 0.\n",
    "    err2 = 0.\n",
    "    predictions = np.zeros_like(Y)\n",
    "    for i in range(len(X)):\n",
    "        closest = np.argsort(\n",
    "            np.array([delta_U_test_train[i, j, :].dot(phi_u)\n",
    "                for j in range(N_train)]))\n",
    "        knn = np.mean(beta[closest[:n_neighbors]], axis=0)\n",
    "        #predictions[i, 0] = X[i, :].T.dot(knn[0])\n",
    "        #predictions[i, 1] = X[i, :].T.dot(knn[1])\n",
    "        if mse:\n",
    "            err1 += functions.logistic_loss(X[i], Y[i, 0], knn[0])\n",
    "            err2 += functions.logistic_loss(X[i], Y[i, 1], knn[1])\n",
    "            #err1 += (Y[i, 0] - predictions[i, 0])**2\n",
    "            #err2 += (Y[i, 1] - predictions[i, 1])**2\n",
    "        elif mae:\n",
    "            err1 += functions.logistic_loss(X[i], Y[i, 0], knn[0])\n",
    "            err2 += functions.logistic_loss(X[i], Y[i, 1], knn[1])\n",
    "            #err1 += np.abs(Y[i, 0] - predictions[i, 0])\n",
    "            #err2 += np.abs(Y[i, 1] - predictions[i, 1])\n",
    "    return (err1+err2) / (2*len(X)), predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting for task #0\n",
      "Fitting Mixture Model for Logistic Regression\n",
      "* Starting EM algorithm for mixture of K=15 least squares models\n",
      "* Beta = 47.31471760694949\n",
      "* Lambda = 0.001\n",
      "* Running at most 2000 iterations\n",
      "* Stopping when complete likelihood improves less than 0.1\n",
      "Obj\tpi1\tpi2\tw11\tw12\tw21\tw22\tbeta1\tbeta2\n",
      "-5780.02\t\t0.06\t0.07\t0.01\t-0.01\t-0.00\t0.01\t47.31\t47.31\n",
      "-5779.62\t\t0.06\t0.07\t0.01\t-0.01\t-0.00\t0.01\t47.31\t47.31\n",
      "-5779.28\t\t0.06\t0.07\t0.01\t-0.01\t-0.00\t0.01\t47.31\t47.31\n",
      "-5779.03\t\t0.06\t0.07\t0.01\t-0.01\t-0.00\t0.01\t47.31\t47.31\n",
      "-5778.86\t\t0.06\t0.07\t0.01\t-0.01\t-0.00\t0.01\t47.31\t47.31\n",
      "-5778.75\t\t0.06\t0.07\t0.01\t-0.01\t-0.00\t0.01\t47.31\t47.31\n",
      "-5778.70\t\t0.06\t0.07\t0.01\t-0.01\t-0.00\t0.01\t47.31\t47.31\n",
      "* Starting EM algorithm for mixture of K=15 least squares models\n",
      "* Beta = 47.31471760694949\n",
      "* Lambda = 0.001\n",
      "* Running at most 2000 iterations\n",
      "* Stopping when complete likelihood improves less than 0.1\n",
      "Obj\tpi1\tpi2\tw11\tw12\tw21\tw22\tbeta1\tbeta2\n",
      "-5780.73\t\t0.07\t0.07\t-0.00\t-0.01\t0.02\t0.01\t47.31\t47.31\n",
      "-5780.49\t\t0.07\t0.07\t-0.00\t-0.01\t0.02\t0.01\t47.31\t47.31\n",
      "-5780.28\t\t0.07\t0.07\t-0.00\t-0.01\t0.02\t0.01\t47.31\t47.31\n",
      "-5780.11\t\t0.07\t0.07\t-0.00\t-0.01\t0.02\t0.01\t47.31\t47.31\n",
      "-5779.98\t\t0.07\t0.07\t-0.00\t-0.01\t0.02\t0.01\t47.31\t47.31\n",
      "-5779.88\t\t0.07\t0.07\t-0.00\t-0.01\t0.02\t0.01\t47.31\t47.31\n",
      "* Starting EM algorithm for mixture of K=15 least squares models\n",
      "* Beta = 47.31471760694949\n",
      "* Lambda = 0.001\n",
      "* Running at most 2000 iterations\n",
      "* Stopping when complete likelihood improves less than 0.1\n",
      "Obj\tpi1\tpi2\tw11\tw12\tw21\tw22\tbeta1\tbeta2\n",
      "-5780.75\t\t0.06\t0.06\t-0.01\t0.01\t0.00\t0.01\t47.31\t47.31\n",
      "-5780.52\t\t0.06\t0.06\t-0.01\t0.01\t0.00\t0.01\t47.31\t47.31\n",
      "-5780.33\t\t0.06\t0.06\t-0.01\t0.01\t0.00\t0.01\t47.31\t47.31\n",
      "-5780.18\t\t0.06\t0.06\t-0.01\t0.01\t0.00\t0.01\t47.31\t47.31\n",
      "-5780.06\t\t0.06\t0.06\t-0.01\t0.01\t0.00\t0.01\t47.31\t47.31\n",
      "-5779.99\t\t0.06\t0.06\t-0.01\t0.01\t0.00\t0.01\t47.31\t47.31\n",
      "* Starting EM algorithm for mixture of K=15 least squares models\n",
      "* Beta = 47.31471760694949\n",
      "* Lambda = 0.001\n",
      "* Running at most 2000 iterations\n",
      "* Stopping when complete likelihood improves less than 0.1\n",
      "Obj\tpi1\tpi2\tw11\tw12\tw21\tw22\tbeta1\tbeta2\n",
      "-5780.47\t\t0.07\t0.07\t-0.01\t0.01\t0.01\t0.00\t47.31\t47.31\n",
      "-5780.18\t\t0.07\t0.07\t-0.01\t0.01\t0.01\t0.00\t47.31\t47.31\n",
      "-5779.93\t\t0.07\t0.07\t-0.01\t0.01\t0.01\t0.00\t47.31\t47.31\n",
      "-5779.73\t\t0.07\t0.07\t-0.01\t0.01\t0.01\t0.00\t47.31\t47.31\n",
      "-5779.59\t\t0.07\t0.07\t-0.01\t0.01\t0.01\t0.00\t47.31\t47.31\n",
      "-5779.49\t\t0.07\t0.07\t-0.01\t0.01\t0.01\t0.00\t47.31\t47.31\n",
      "* Starting EM algorithm for mixture of K=15 least squares models\n",
      "* Beta = 47.31471760694949\n",
      "* Lambda = 0.001\n",
      "* Running at most 2000 iterations\n",
      "* Stopping when complete likelihood improves less than 0.1\n",
      "Obj\tpi1\tpi2\tw11\tw12\tw21\tw22\tbeta1\tbeta2\n",
      "-5780.75\t\t0.07\t0.07\t-0.00\t-0.00\t-0.00\t0.00\t47.31\t47.31\n",
      "-5780.52\t\t0.07\t0.07\t-0.00\t-0.00\t-0.00\t0.00\t47.31\t47.31\n",
      "-5780.33\t\t0.07\t0.07\t-0.00\t-0.00\t-0.00\t0.00\t47.31\t47.31\n",
      "-5780.18\t\t0.07\t0.07\t-0.00\t-0.00\t-0.00\t0.00\t47.31\t47.31\n",
      "-5780.08\t\t0.07\t0.07\t-0.00\t-0.00\t-0.00\t0.00\t47.31\t47.31\n",
      "-5780.01\t\t0.07\t0.07\t-0.00\t-0.00\t-0.00\t0.00\t47.31\t47.31\n",
      "-Took 17.90 seconds\n",
      "Fitting for task #1\n",
      "Fitting Mixture Model for Logistic Regression\n",
      "* Starting EM algorithm for mixture of K=15 least squares models\n",
      "* Beta = 48.021694308256635\n",
      "* Lambda = 0.001\n",
      "* Running at most 2000 iterations\n",
      "* Stopping when complete likelihood improves less than 0.1\n",
      "Obj\tpi1\tpi2\tw11\tw12\tw21\tw22\tbeta1\tbeta2\n",
      "-5781.12\t\t0.07\t0.07\t0.01\t-0.01\t-0.01\t-0.01\t48.02\t48.02\n",
      "-5781.01\t\t0.07\t0.07\t0.01\t-0.01\t-0.00\t-0.01\t48.02\t48.02\n",
      "-5780.92\t\t0.07\t0.07\t0.01\t-0.01\t-0.00\t-0.01\t48.02\t48.02\n",
      "* Starting EM algorithm for mixture of K=15 least squares models\n",
      "* Beta = 48.021694308256635\n",
      "* Lambda = 0.001\n",
      "* Running at most 2000 iterations\n",
      "* Stopping when complete likelihood improves less than 0.1\n",
      "Obj\tpi1\tpi2\tw11\tw12\tw21\tw22\tbeta1\tbeta2\n",
      "-5780.55\t\t0.07\t0.07\t0.01\t-0.01\t-0.02\t-0.01\t48.02\t48.02\n",
      "-5780.30\t\t0.07\t0.07\t0.01\t-0.01\t-0.02\t-0.01\t48.02\t48.02\n",
      "-5780.09\t\t0.07\t0.07\t0.01\t-0.01\t-0.02\t-0.01\t48.02\t48.02\n",
      "-5779.91\t\t0.07\t0.07\t0.01\t-0.01\t-0.02\t-0.01\t48.02\t48.02\n",
      "-5779.75\t\t0.07\t0.07\t0.01\t-0.01\t-0.02\t-0.01\t48.02\t48.02\n",
      "-5779.61\t\t0.07\t0.07\t0.01\t-0.01\t-0.02\t-0.01\t48.02\t48.02\n",
      "-5779.48\t\t0.07\t0.07\t0.01\t-0.01\t-0.02\t-0.01\t48.02\t48.02\n",
      "-5779.34\t\t0.07\t0.07\t0.01\t-0.01\t-0.02\t-0.01\t48.02\t48.02\n",
      "-5779.18\t\t0.07\t0.07\t0.01\t-0.01\t-0.02\t-0.01\t48.02\t48.02\n",
      "-5778.97\t\t0.07\t0.07\t0.01\t-0.01\t-0.02\t-0.01\t48.02\t48.02\n",
      "-5778.71\t\t0.07\t0.06\t0.01\t-0.01\t-0.02\t-0.01\t48.02\t48.02\n",
      "-5778.37\t\t0.07\t0.06\t0.01\t-0.01\t-0.02\t-0.01\t48.02\t48.02\n",
      "-5777.93\t\t0.07\t0.06\t0.01\t-0.01\t-0.02\t-0.01\t48.02\t48.02\n",
      "-5777.37\t\t0.06\t0.06\t0.01\t-0.01\t-0.02\t-0.01\t48.02\t48.02\n",
      "-5776.67\t\t0.06\t0.06\t0.01\t-0.01\t-0.02\t-0.01\t48.02\t48.02\n",
      "-5775.82\t\t0.06\t0.06\t0.01\t-0.01\t-0.02\t-0.01\t48.02\t48.02\n",
      "-5774.82\t\t0.06\t0.06\t0.01\t-0.01\t-0.02\t-0.01\t48.02\t48.02\n",
      "-5773.70\t\t0.06\t0.06\t0.01\t-0.01\t-0.02\t-0.01\t48.02\t48.02\n",
      "-5772.47\t\t0.06\t0.06\t0.01\t-0.01\t-0.02\t-0.01\t48.02\t48.02\n",
      "-5771.21\t\t0.06\t0.06\t0.01\t-0.01\t-0.02\t-0.01\t48.02\t48.02\n",
      "-5769.95\t\t0.06\t0.06\t0.01\t-0.01\t-0.02\t-0.01\t48.02\t48.02\n",
      "-5768.76\t\t0.06\t0.06\t0.01\t-0.01\t-0.02\t-0.01\t48.02\t48.02\n",
      "-5767.71\t\t0.06\t0.06\t0.01\t-0.01\t-0.02\t-0.01\t48.02\t48.02\n",
      "-5766.84\t\t0.06\t0.06\t0.01\t-0.01\t-0.02\t-0.01\t48.02\t48.02\n",
      "-5766.20\t\t0.06\t0.06\t0.01\t-0.01\t-0.02\t-0.01\t48.02\t48.02\n",
      "-5765.83\t\t0.06\t0.06\t0.01\t-0.01\t-0.02\t-0.01\t48.02\t48.02\n",
      "-5765.75\t\t0.06\t0.06\t0.01\t-0.01\t-0.02\t-0.01\t48.02\t48.02\n",
      "* Starting EM algorithm for mixture of K=15 least squares models\n",
      "* Beta = 48.021694308256635\n",
      "* Lambda = 0.001\n",
      "* Running at most 2000 iterations\n",
      "* Stopping when complete likelihood improves less than 0.1\n",
      "Obj\tpi1\tpi2\tw11\tw12\tw21\tw22\tbeta1\tbeta2\n",
      "-5781.11\t\t0.07\t0.07\t-0.01\t0.00\t0.00\t0.01\t48.02\t48.02\n",
      "-5780.99\t\t0.07\t0.07\t-0.01\t0.00\t0.00\t0.01\t48.02\t48.02\n",
      "-5780.89\t\t0.07\t0.07\t-0.01\t0.00\t0.00\t0.01\t48.02\t48.02\n",
      "-5780.81\t\t0.07\t0.07\t-0.01\t0.00\t0.00\t0.01\t48.02\t48.02\n",
      "* Starting EM algorithm for mixture of K=15 least squares models\n",
      "* Beta = 48.021694308256635\n",
      "* Lambda = 0.001\n",
      "* Running at most 2000 iterations\n",
      "* Stopping when complete likelihood improves less than 0.1\n",
      "Obj\tpi1\tpi2\tw11\tw12\tw21\tw22\tbeta1\tbeta2\n",
      "-5780.69\t\t0.07\t0.07\t-0.01\t-0.03\t0.01\t-0.01\t48.02\t48.02\n",
      "-5780.47\t\t0.07\t0.07\t-0.01\t-0.03\t0.01\t-0.01\t48.02\t48.02\n",
      "-5780.29\t\t0.07\t0.07\t-0.01\t-0.03\t0.01\t-0.01\t48.02\t48.02\n",
      "-5780.13\t\t0.07\t0.07\t-0.01\t-0.03\t0.01\t-0.01\t48.02\t48.02\n",
      "-5780.00\t\t0.07\t0.07\t-0.01\t-0.03\t0.01\t-0.01\t48.02\t48.02\n",
      "-5779.88\t\t0.07\t0.07\t-0.01\t-0.03\t0.01\t-0.01\t48.02\t48.02\n",
      "-5779.77\t\t0.07\t0.06\t-0.01\t-0.03\t0.01\t-0.01\t48.02\t48.02\n",
      "-5779.65\t\t0.07\t0.06\t-0.01\t-0.03\t0.01\t-0.01\t48.02\t48.02\n",
      "-5779.51\t\t0.07\t0.06\t-0.01\t-0.03\t0.01\t-0.01\t48.02\t48.02\n",
      "-5779.34\t\t0.07\t0.06\t-0.01\t-0.03\t0.01\t-0.01\t48.02\t48.02\n",
      "-5779.11\t\t0.07\t0.06\t-0.01\t-0.03\t0.01\t-0.01\t48.02\t48.02\n",
      "-5778.81\t\t0.07\t0.06\t-0.01\t-0.03\t0.01\t-0.01\t48.02\t48.02\n",
      "-5778.43\t\t0.07\t0.06\t-0.01\t-0.03\t0.01\t-0.01\t48.02\t48.02\n",
      "-5777.94\t\t0.07\t0.06\t-0.01\t-0.03\t0.01\t-0.01\t48.02\t48.02\n",
      "-5777.32\t\t0.07\t0.06\t-0.01\t-0.03\t0.01\t-0.01\t48.02\t48.02\n",
      "-5776.57\t\t0.06\t0.06\t-0.01\t-0.03\t0.01\t-0.01\t48.02\t48.02\n",
      "-5775.69\t\t0.06\t0.06\t-0.01\t-0.03\t0.01\t-0.01\t48.02\t48.02\n",
      "-5774.71\t\t0.06\t0.06\t-0.01\t-0.03\t0.01\t-0.01\t48.02\t48.02\n",
      "-5773.66\t\t0.06\t0.06\t-0.01\t-0.03\t0.01\t-0.01\t48.02\t48.02\n",
      "-5772.61\t\t0.06\t0.06\t-0.01\t-0.03\t0.01\t-0.01\t48.02\t48.02\n",
      "-5771.61\t\t0.06\t0.06\t-0.01\t-0.03\t0.01\t-0.01\t48.02\t48.02\n",
      "-5770.73\t\t0.06\t0.06\t-0.01\t-0.03\t0.01\t-0.01\t48.02\t48.02\n",
      "-5770.01\t\t0.06\t0.06\t-0.01\t-0.03\t0.01\t-0.01\t48.02\t48.02\n",
      "-5769.50\t\t0.06\t0.06\t-0.01\t-0.03\t0.01\t-0.01\t48.02\t48.02\n",
      "-5769.19\t\t0.06\t0.06\t-0.01\t-0.03\t0.01\t-0.01\t48.02\t48.02\n",
      "-5769.09\t\t0.06\t0.06\t-0.01\t-0.03\t0.01\t-0.01\t48.02\t48.02\n",
      "-5769.16\t\t0.06\t0.06\t-0.01\t-0.03\t0.01\t-0.01\t48.02\t48.02\n",
      "* Starting EM algorithm for mixture of K=15 least squares models\n",
      "* Beta = 48.021694308256635\n",
      "* Lambda = 0.001\n",
      "* Running at most 2000 iterations\n",
      "* Stopping when complete likelihood improves less than 0.1\n",
      "Obj\tpi1\tpi2\tw11\tw12\tw21\tw22\tbeta1\tbeta2\n",
      "-5780.77\t\t0.07\t0.07\t-0.01\t-0.00\t0.01\t-0.00\t48.02\t48.02\n",
      "-5780.61\t\t0.07\t0.07\t-0.01\t-0.00\t0.01\t-0.00\t48.02\t48.02\n",
      "-5780.50\t\t0.07\t0.07\t-0.01\t-0.00\t0.01\t-0.00\t48.02\t48.02\n",
      "-5780.43\t\t0.07\t0.07\t-0.01\t-0.00\t0.01\t-0.00\t48.02\t48.02\n",
      "-Took 39.01 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAETtJREFUeJzt3X+MXWWdx/H3Z1tF0FUgzHZr22wb02gK0UUbFjUxZlmX\nrhjKX6TGH3UlNhtZo8bEtJqsf3WD0bhqdnHT+IMaCaRBDY2KS1M1ZuMiDoJCWyuNgG0tdFyiuJqg\nxe/+cQ96LZ1Oe8907kyf9yuZ3Oc85znn+c70znzu+XFvU1VIktr0Z+MuQJI0PoaAJDXMEJCkhhkC\nktQwQ0CSGmYISFLDDAFJapghIEkNMwQkqWGLx13ATC666KJauXLluMuQpAXlnnvu+XlVTcw0bt6H\nwMqVK5mcnBx3GZK0oCR55FTGeTpIkhpmCEhSwwwBSWqYISBJDTMEJKlhhoAkNcwQkKSGGQKS1DBD\nQJIaNu/fMazTs3LzV2d1fw/fcNWs7k/S/OKRgCQ1zBCQpIYZApLUMENAkhpmCEhSwwwBSWqYISBJ\nDTMEJKlhhoAkNcwQkKSGGQKS1DBDQJIaNmMIJPlskqNJHhjq+0iSHyX5YZIvJzl/aN2WJAeS7E9y\n5VD/K5Lc3637ZJLM/rcjSTodp3IkcBOw7ri+XcAlVfVS4MfAFoAka4ANwMXdNjcmWdRt8yngHcDq\n7uv4fUqS5tiMIVBV3wYeP67vzqo61i3eBSzv2uuBW6vqyap6CDgAXJZkKfD8qrqrqgr4PHDNbH0T\nkqTRzMY1gbcDd3TtZcDBoXWHur5lXfv4fknSGPUKgSQfBI4BN89OOX/Y76Ykk0kmp6amZnPXkqQh\nI4dAkrcBbwDe1J3iATgMrBgatrzrO8wfTxkN959QVW2rqrVVtXZiYmLUEiVJMxgpBJKsA94PXF1V\nvxlatRPYkOScJKsYXAC+u6qOAE8kuby7K+itwO09a5ck9TTj/zGc5BbgtcBFSQ4BH2JwN9A5wK7u\nTs+7quqfqmpPkh3AXgania6vqqe6Xb2TwZ1G5zK4hnAHkqSxmjEEquqNJ+j+zEnGbwW2nqB/Erjk\ntKqTJJ1RvmNYkhpmCEhSwwwBSWqYISBJDTMEJKlhhoAkNcwQkKSGGQKS1DBDQJIaZghIUsMMAUlq\nmCEgSQ0zBCSpYYaAJDXMEJCkhhkCktQwQ0CSGmYISFLDDAFJapghIEkNMwQkqWGGgCQ1zBCQpIbN\nGAJJPpvkaJIHhvouTLIryYPd4wVD67YkOZBkf5Irh/pfkeT+bt0nk2T2vx1J0uk4lSOBm4B1x/Vt\nBnZX1Wpgd7dMkjXABuDibpsbkyzqtvkU8A5gdfd1/D4lSXNsxhCoqm8Djx/XvR7Y3rW3A9cM9d9a\nVU9W1UPAAeCyJEuB51fVXVVVwOeHtpEkjcmo1wSWVNWRrv0osKRrLwMODo071PUt69rH959Qkk1J\nJpNMTk1NjViiJGkmvS8Md6/saxZqGd7ntqpaW1VrJyYmZnPXkqQho4bAY90pHrrHo13/YWDF0Ljl\nXd/hrn18vyRpjEYNgZ3Axq69Ebh9qH9DknOSrGJwAfju7tTRE0ku7+4KeuvQNpKkMVk804AktwCv\nBS5Kcgj4EHADsCPJdcAjwLUAVbUnyQ5gL3AMuL6qnup29U4GdxqdC9zRfUmSxmjGEKiqN06z6opp\nxm8Ftp6gfxK45LSqkySdUb5jWJIaZghIUsMMAUlqmCEgSQ0zBCSpYYaAJDXMEJCkhhkCktQwQ0CS\nGmYISFLDDAFJapghIEkNMwQkqWGGgCQ1zBCQpIYZApLUMENAkhpmCEhSwwwBSWqYISBJDTMEJKlh\nhoAkNaxXCCTZkmRvkgeS3JLkOUkuTLIryYPd4wXHjT+QZH+SK/uXL0nqY+QQSLIS2AS8oqouARYB\nG4DNwO6qWg3s7pZJsqZbfzGwDrgxyaI+xUuS+ulzJPAE8Dvg3CSLgfOAnwHrge3dmO3ANV17PXBr\nVT1ZVQ8BB4DLeswvSepp5BCoqseBjwI/BY4Av6yqO4ElVXWkG/YosKRrLwMODu3iUNcnSRqTPqeD\nXgS8F1gFvBB4bpI3D4+pqgJqhH1vSjKZZHJqamrUEiVJM+hzOmgt8J2qmqqq3wFfAl4FPJZkKUD3\neLQbfxhYMbT98q7vGapqW1Wtraq1ExMTPUqUJJ1MnxDYD1ye5LwkAa4A9gE7gY3dmI3A7V17J7Ah\nyTlJVgGrgbt7zC9J6mnxqBtW1X1JPg9MAr8H7gW2Ac8DdiS5DngEuLYbvyfJDmAvcAy4vqqe6lm/\nJKmHkUMAoKo+DHz4uO4nGRwVnGj8VmBrnzklSbPHdwxLUsMMAUlqmCEgSQ0zBCSpYYaAJDXMEJCk\nhhkCktQwQ0CSGmYISFLDDAFJapghIEkNMwQkqWGGgCQ1rNeniErzwcrNX53V/T18w1Wzuj9pPvNI\nQJIaZghIUsMMAUlqmCEgSQ0zBCSpYYaAJDXMEJCkhhkCktQwQ0CSGtYrBJKcn+S2JD9Ksi/JK5Nc\nmGRXkge7xwuGxm9JciDJ/iRX9i9fktRH3yOBTwBfr6qXAC8D9gGbgd1VtRrY3S2TZA2wAbgYWAfc\nmGRRz/klST2MHAJJXgC8BvgMQFX9tqp+AawHtnfDtgPXdO31wK1V9WRVPQQcAC4bdX5JUn99jgRW\nAVPA55Lcm+TTSZ4LLKmqI92YR4ElXXsZcHBo+0NdnyRpTPqEwGLg5cCnqupS4Nd0p36eVlUF1Onu\nOMmmJJNJJqempnqUKEk6mT4hcAg4VFXf7ZZvYxAKjyVZCtA9Hu3WHwZWDG2/vOt7hqraVlVrq2rt\nxMREjxIlSSczcghU1aPAwSQv7rquAPYCO4GNXd9G4PauvRPYkOScJKuA1cDdo84vSeqv738q8y7g\n5iTPBn4C/CODYNmR5DrgEeBagKrak2QHg6A4BlxfVU/1nF+S1EOvEKiq+4C1J1h1xTTjtwJb+8wp\nSZo9vmNYkhpmCEhSwwwBSWqYISBJDTMEJKlhhoAkNcwQkKSGGQKS1DBDQJIaZghIUsMMAUlqmCEg\nSQ0zBCSpYYaAJDXMEJCkhhkCktQwQ0CSGmYISFLDDAFJapghIEkNMwQkqWGGgCQ1zBCQpIb1DoEk\ni5Lcm+Qr3fKFSXYlebB7vGBo7JYkB5LsT3Jl37klSf3MxpHAu4F9Q8ubgd1VtRrY3S2TZA2wAbgY\nWAfcmGTRLMwvSRpRrxBIshy4Cvj0UPd6YHvX3g5cM9R/a1U9WVUPAQeAy/rML0nqp++RwMeB9wO/\nH+pbUlVHuvajwJKuvQw4ODTuUNf3DEk2JZlMMjk1NdWzREnSdEYOgSRvAI5W1T3TjamqAup0911V\n26pqbVWtnZiYGLVESdIMFvfY9tXA1UleDzwHeH6SLwCPJVlaVUeSLAWOduMPAyuGtl/e9UmSxmTk\nI4Gq2lJVy6tqJYMLvt+oqjcDO4GN3bCNwO1deyewIck5SVYBq4G7R65cktRbnyOB6dwA7EhyHfAI\ncC1AVe1JsgPYCxwDrq+qp87A/JKkUzQrIVBV3wK+1bX/F7himnFbga2zMackqT/fMSxJDTMEJKlh\nhoAkNcwQkKSGGQKS1DBDQJIaZghIUsMMAUlqmCEgSQ0zBCSpYYaAJDXMEJCkhhkCktQwQ0CSGmYI\nSFLDDAFJapghIEkNMwQkqWGGgCQ1zBCQpIYZApLUMENAkho2cggkWZHkm0n2JtmT5N1d/4VJdiV5\nsHu8YGibLUkOJNmf5MrZ+AYkSaPrcyRwDHhfVa0BLgeuT7IG2AzsrqrVwO5umW7dBuBiYB1wY5JF\nfYqXJPUzcghU1ZGq+n7X/hWwD1gGrAe2d8O2A9d07fXArVX1ZFU9BBwALht1fklSf7NyTSDJSuBS\n4LvAkqo60q16FFjStZcBB4c2O9T1SZLGpHcIJHke8EXgPVX1xPC6qiqgRtjnpiSTSSanpqb6lihJ\nmkavEEjyLAYBcHNVfanrfizJ0m79UuBo138YWDG0+fKu7xmqaltVra2qtRMTE31KlCSdRJ+7gwJ8\nBthXVR8bWrUT2Ni1NwK3D/VvSHJOklXAauDuUeeXJPW3uMe2rwbeAtyf5L6u7wPADcCOJNcBjwDX\nAlTVniQ7gL0M7iy6vqqe6jG/JKmnkUOgqv4byDSrr5hmm63A1lHnlCTNLt8xLEkNMwQkqWGGgCQ1\nzBCQpIYZApLUMENAkhpmCEhSwwwBSWqYISBJDTMEJKlhhoAkNcwQkKSGGQKS1DBDQJIaZghIUsMM\nAUlqmCEgSQ0zBCSpYYaAJDXMEJCkhhkCktQwQ0CSGmYISFLD5jwEkqxLsj/JgSSb53p+SdIfLZ7L\nyZIsAv4DeB1wCPhekp1VtfdMzLdy81dndX8P33DVrO5vIfBnqPlgtp+H4HPxaXMaAsBlwIGq+glA\nkluB9cAZCYGF4Ew8ueezhfD9Gnz9LYR/Zw3MdQgsAw4OLR8C/maOaxiZT2yNwufN/DTf/13m6sXD\nXIfAKUmyCdjULf5fkv0j7uoi4OezU9UZt5BqhYVV70KqFRZWvQupVlhA9ebDvWv9q1MZNNchcBhY\nMbS8vOv7E1W1DdjWd7Ikk1W1tu9+5sJCqhUWVr0LqVZYWPUupFphYdU7V7XO9d1B3wNWJ1mV5NnA\nBmDnHNcgSerM6ZFAVR1L8s/AfwGLgM9W1Z65rEGS9Edzfk2gqr4GfG2Oput9SmkOLaRaYWHVu5Bq\nhYVV70KqFRZWvXNSa6pqLuaRJM1DfmyEJDXsrAyBhfTRFElWJPlmkr1J9iR597hrmkmSRUnuTfKV\ncdcykyTnJ7ktyY+S7EvyynHXNJ0kW7rnwQNJbknynHHXNCzJZ5McTfLAUN+FSXYlebB7vGCcNQ6b\npt6PdM+FHyb5cpLzx1nj005U69C69yWpJBedibnPuhAY+miKfwDWAG9Msma8VZ3UMeB9VbUGuBy4\nfp7XC/BuYN+4izhFnwC+XlUvAV7GPK07yUoG7415RVVdwuDGiQ3jrOkEbgLWHde3GdhdVauB3d3y\nfHETz6x3F3BJVb0U+DGwZa6LmsZNPLNWkqwA/h746Zma+KwLAYY+mqKqfgs8/dEU81JVHamq73ft\nXzH4I7VsvFVNL8ly4Crg0+OuZSZJXgC8BvgMQFX9tqp+Md6qpvUE8Dvg3CSLgfOAn423pD9VVd8G\nHj+uez2wvWtvB66Z06JO4kT1VtWdVXWsW7yLwXuVxm6any3AvwHvB87YxduzMQRO9NEU8/aP6rDu\n1eClwHfHW8lJfZzBk/L34y7kFKwCpoDPdaevPp3kueMu6kSq6nHgowxe8R0BfllVd463qlOypKqO\ndO1HgSXjLOY0vR24Y9xFTCfJeuBwVf3gTM5zNobAgpTkecAXgfdU1RPjrudEkrwBOFpV94y7llO0\nGHg58KmquhT4NfPrdMUfJHkR8F4GwfVC4LlJ3jzeqk5PDW41XBC3Gyb5IINTsTePu5YTSXIe8AHg\nX870XGdjCJzSR1PMJ0mexSAAbq6qL427npN4NXB1kocZnGb72yRfGG9JJ3UIOFRVTx9Z3cYgFOaj\ntcB3qmqqqn4HfAl41ZhrOhWPJVkK0D0eHXM9M0ryNuANwJtq/t4j/yIGLwh+0P2+LQe+n+QvZ3ui\nszEEFtRHUyQJg3PW+6rqY+Ou52SqaktVLa+qlQx+rt+oqnn7arWqHgUOJnlx13UF8/djy/cDlyc5\nr3tOXME8vYh9nJ3Axq69Ebh9jLXMKMk6Bqczr66q34y7nulU1f1V9RdVtbL7fTsEvLx7Ts+qsy4E\nuos+T380xT5gxzz/aIpXA29h8Kr6vu7r9eMu6izyLuDmJD8E/hr41zHXc0JVdR/weWASuJ/B7+a8\nendrkluA/wFenORQkuuAG4DXJXkQ+LtueV6Ypt5/B/4c2NX9rv3nWIvsTFPr3Mw9f4+GJEln2ll3\nJCBJOnWGgCQ1zBCQpIYZApLUMENAkhpmCEhSwwwBSWqYISBJDft/NGGVtRAPa9MAAAAASUVORK5C\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fae31a0a2e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fae6d8cee10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "refit_mixture=True\n",
    "if refit_mixture:\n",
    "    mixture_beta = []\n",
    "    n_classes = 15\n",
    "    for i in range(Y_train.shape[1]-1):\n",
    "        print(\"Fitting for task #{}\".format(i))\n",
    "        task_beta, task_assignments = baselines.mixture_model_logistic(\n",
    "            X_train, np.expand_dims(Y_train[:, i], 1),\n",
    "            n_classes=n_classes, lam=1e-3, n_restarts=5, verbosity=100,\n",
    "            init_lr=2e-1, eps=1e-1)\n",
    "        mixture_beta.append(task_beta)\n",
    "        plt.figure()\n",
    "        plt.hist(task_assignments, bins=n_classes)\n",
    "    mixture_beta.append(np.zeros_like(mixture_beta[0]))\n",
    "    mixture_beta = np.swapaxes(np.array(mixture_beta), 0, 1)\n",
    "    np.save(\"beta_mixture.npy\", mixture_beta)\n",
    "else:\n",
    "    mixture_beta = np.load(\"beta_mixture.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2135, 3, 6)\n",
      "(2135, 6)\n"
     ]
    }
   ],
   "source": [
    "print(mixture_beta.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_preds_mix = np.array([np.tensordot(X_train[i], mixture_beta[i].T, axes=1) for i in range(len(X_train))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2135, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_preds_mix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.205 -0.044  0.   ]\n",
      " [-0.205 -0.06   0.   ]\n",
      " [-0.351  0.9    0.   ]\n",
      " ...\n",
      " [-0.351  0.809  0.   ]\n",
      " [-0.351  0.9    0.   ]\n",
      " [-0.351  0.9    0.   ]]\n"
     ]
    }
   ],
   "source": [
    "print(train_preds_mix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.472 0.519 0.009]\n",
      " [0.504 0.485 0.012]\n",
      " [0.252 0.743 0.005]\n",
      " ...\n",
      " [0.282 0.695 0.023]\n",
      " [0.293 0.699 0.008]\n",
      " [0.258 0.734 0.008]]\n"
     ]
    }
   ],
   "source": [
    "print(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mapped_train_preds = np.exp(train_preds_mix) / (1 + np.exp(train_preds_mix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01184846937364287\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "a = mean_squared_error(Y_train[:, 0], mapped_train_preds[:, 0])\n",
    "b = mean_squared_error(Y_train[:, 1], mapped_train_preds[:, 1])\n",
    "print((a+b)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43758509404344187\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "a = r2_score(Y_train[:, 0], mapped_train_preds[:, 0])\n",
    "b = r2_score(Y_train[:, 1], mapped_train_preds[:, 1])\n",
    "print((a+b)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(logistic_loss, mixture_preds) = calc_test_err(mixture_beta, X_test, Y_test,\n",
    "                                               delta_U_test_train, 1, np.ones((delta_U_test_train.shape[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mapped_test_preds = np.exp(mixture_preds) / (1 + np.exp(mixture_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0301693467761825\n",
      "-0.5696919577567529\n"
     ]
    }
   ],
   "source": [
    "a = mean_squared_error(Y_test[:, 0], mapped_test_preds[:, 0])\n",
    "b = mean_squared_error(Y_test[:, 1], mapped_test_preds[:, 1])\n",
    "print((a+b)/2)\n",
    "\n",
    "a = r2_score(Y_test[:, 0], mapped_test_preds[:, 0])\n",
    "b = r2_score(Y_test[:, 1], mapped_test_preds[:, 1])\n",
    "print((a+b)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting for task #0\n",
      "Fitting Varying Coefficients with Logistic Output.\n",
      "Restart 1 of 1\n",
      "Iteration: 0 Total Loss:0.693 Pred:0.693 l1:0.000\n",
      "Iteration: 10 Total Loss:0.678 Pred:0.678 l1:0.000\n",
      "Iteration: 20 Total Loss:0.672 Pred:0.672 l1:0.000\n",
      "Iteration: 30 Total Loss:0.671 Pred:0.670 l1:0.000\n",
      "Iteration: 40 Total Loss:0.670 Pred:0.670 l1:0.000\n",
      "Iteration: 50 Total Loss:0.670 Pred:0.670 l1:0.000\n",
      "Iteration: 60 Total Loss:0.670 Pred:0.670 l1:0.000\n",
      "Iteration: 70 Total Loss:0.670 Pred:0.670 l1:0.000\n",
      "Iteration: 80 Total Loss:0.670 Pred:0.670 l1:0.000\n",
      "Iteration: 90 Total Loss:0.670 Pred:0.670 l1:0.000\n",
      "Iteration: 100 Total Loss:0.670 Pred:0.670 l1:0.000\n",
      "Iteration: 110 Total Loss:0.670 Pred:0.670 l1:0.000\n",
      "Iteration: 120 Total Loss:0.670 Pred:0.670 l1:0.000\n",
      "Reached local minimum at iteration 128.\n",
      "Took 6.640 seconds.\n",
      "** New best solution **\n",
      "Took 6.64 seconds\n",
      "[[-0.003  0.     0.003  0.     0.    -0.439]\n",
      " [-0.003  0.     0.003  0.     0.    -0.439]\n",
      " [-0.003  0.     0.003  0.     0.    -0.439]\n",
      " ...\n",
      " [-0.003  0.     0.003  0.     0.    -0.439]\n",
      " [-0.003  0.     0.003  0.     0.    -0.439]\n",
      " [-0.003  0.     0.003  0.     0.    -0.439]]\n",
      "[[-2.614e-03  0.000e+00  2.614e-03  0.000e+00  0.000e+00 -4.391e-01]\n",
      " [ 8.649e-06  0.000e+00 -8.649e-06  0.000e+00  0.000e+00  1.474e-03]\n",
      " [-5.071e-06  0.000e+00  5.071e-06  0.000e+00  0.000e+00 -8.732e-04]]\n",
      "Fitting for task #1\n",
      "Fitting Varying Coefficients with Logistic Output.\n",
      "Restart 1 of 1\n",
      "Iteration: 0 Total Loss:0.693 Pred:0.693 l1:0.000\n",
      "Iteration: 10 Total Loss:0.681 Pred:0.681 l1:0.000\n",
      "Iteration: 20 Total Loss:0.676 Pred:0.676 l1:0.000\n",
      "Iteration: 30 Total Loss:0.675 Pred:0.675 l1:0.000\n",
      "Iteration: 40 Total Loss:0.674 Pred:0.674 l1:0.000\n",
      "Iteration: 50 Total Loss:0.674 Pred:0.674 l1:0.000\n",
      "Iteration: 60 Total Loss:0.674 Pred:0.674 l1:0.000\n",
      "Iteration: 70 Total Loss:0.674 Pred:0.674 l1:0.000\n",
      "Iteration: 80 Total Loss:0.674 Pred:0.674 l1:0.000\n",
      "Iteration: 90 Total Loss:0.674 Pred:0.674 l1:0.000\n",
      "Iteration: 100 Total Loss:0.674 Pred:0.674 l1:0.000\n",
      "Iteration: 110 Total Loss:0.674 Pred:0.674 l1:0.000\n",
      "Iteration: 120 Total Loss:0.674 Pred:0.674 l1:0.000\n",
      "Reached local minimum at iteration 125.\n",
      "Took 6.546 seconds.\n",
      "** New best solution **\n",
      "Took 6.55 seconds\n",
      "[[ 0.002  0.    -0.002  0.     0.     0.394]\n",
      " [ 0.002  0.    -0.002  0.     0.     0.394]\n",
      " [ 0.002  0.    -0.002  0.     0.     0.394]\n",
      " ...\n",
      " [ 0.002  0.    -0.002  0.     0.     0.394]\n",
      " [ 0.002  0.    -0.002  0.     0.     0.394]\n",
      " [ 0.002  0.    -0.002  0.     0.     0.394]]\n",
      "[[ 2.343e-03  0.000e+00 -2.343e-03  0.000e+00  0.000e+00  3.936e-01]\n",
      " [-8.367e-06  0.000e+00  8.367e-06  0.000e+00  0.000e+00 -1.426e-03]\n",
      " [ 4.894e-06  0.000e+00 -4.894e-06  0.000e+00  0.000e+00  8.429e-04]]\n",
      "(2135, 3, 6)\n"
     ]
    }
   ],
   "source": [
    "refit_vc = True\n",
    "if refit_vc:\n",
    "    vc_beta = []\n",
    "    vc_z = []\n",
    "    for i in range(Y_train.shape[1]-1):\n",
    "        print(\"Fitting for task #{}\".format(i))\n",
    "        init_Z = np.zeros((Z_train.shape[1]+1, X_train.shape[1]))\n",
    "        #init_Z[0, -1] = np.mean(Y_train[:, i]) # intercept\n",
    "        task_beta, task_Z = baselines.vc_logistic(\n",
    "            X_train, np.expand_dims(Y_train[:, i], 1),\n",
    "            Z_train, lam=1e-5, lr=1e-4, verbosity=10,\n",
    "            n_restarts=1, init_Z=init_Z, max_iters=10000)\n",
    "        print(task_beta)\n",
    "        print(task_Z)\n",
    "        vc_z.append(task_Z)\n",
    "        vc_beta.append(task_beta)\n",
    "    vc_beta.append(np.zeros_like(vc_beta[0]))\n",
    "    vc_beta = np.swapaxes(np.array(vc_beta), 0, 1)\n",
    "    print(vc_beta.shape)\n",
    "    np.save(\"beta_vc.npy\", vc_beta)\n",
    "else:\n",
    "    vc_beta = np.load(\"beta_vc.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2135, 2)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD8CAYAAABpcuN4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSV0GhSSp6/8DGgjSXa6cE4AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fae0429e128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Z_bordered = np.hstack((Z_train, np.ones((len(Z_train), 1))))\n",
    "print(Z_train.shape)\n",
    "vc_beta = np.array([z.dot(vc_z) for z in Z_bordered])\n",
    "vc_preds = np.array([X_train[i].dot(vc_beta[i].T) for i in range(len(X_train))])\n",
    "plt.hist(vc_preds[:, 0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "calc_mse = lambda a,b,c,d,e,f: calc_test_err(a,b,c,d,e,f,mse=True, mae=False)\n",
    "\n",
    "vc_preds_train = np.array([np.tensordot(X_train[i], vc_beta[i].T, axes=1) for i in range(len(X_train))])\n",
    "mapped_vc_preds_train = np.exp(vc_preds_train / (1+vc_preds_train))\n",
    "\n",
    "(vc_mse_test, vc_preds_test) = calc_mse(vc_beta, X_test, Y_test, delta_U_test_train, 1, np.ones((K)))\n",
    "mapped_vc_preds_test = np.exp(vc_preds_test / (1+vc_preds_test))\n",
    "#print(calc_mse(vc_beta, X_train, Y_train, delta_U_train_train, 1, np.ones((K))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.439  0.395  0.   ]\n",
      " [-0.439  0.395  0.   ]\n",
      " [-0.439  0.395  0.   ]\n",
      " ...\n",
      " [-0.439  0.395  0.   ]\n",
      " [-0.439  0.395  0.   ]\n",
      " [-0.439  0.395  0.   ]]\n",
      "0.7116398722645113 0.06188901590981489 0.3867644440871631\n",
      "0.2893965472868731\n",
      "-12.888338461262324\n"
     ]
    }
   ],
   "source": [
    "a = mean_squared_error(Y_train[:, 0], vc_preds_train[:, 0])\n",
    "b = mean_squared_error(Y_train[:, 1], vc_preds_train[:, 1])\n",
    "print(a, b, (a+b)/2)\n",
    "\n",
    "\n",
    "a = mean_squared_error(Y_train[:, 0], mapped_vc_preds_train[:, 0])\n",
    "b = mean_squared_error(Y_train[:, 1], mapped_vc_preds_train[:, 1])\n",
    "print((a+b)/2)\n",
    "\n",
    "a = r2_score(Y_train[:, 0], mapped_vc_preds_train[:, 0])\n",
    "b = r2_score(Y_train[:, 1], mapped_vc_preds_train[:, 1])\n",
    "print((a+b)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2856080950759524\n",
      "-13.82112365865072\n"
     ]
    }
   ],
   "source": [
    "a = mean_squared_error(Y_test[:, 0], mapped_vc_preds_test[:, 0])\n",
    "b = mean_squared_error(Y_test[:, 1], mapped_vc_preds_test[:, 1])\n",
    "print((a+b)/2)\n",
    "\n",
    "a = r2_score(Y_test[:, 0], mapped_vc_preds_test[:, 0])\n",
    "b = r2_score(Y_test[:, 1], mapped_vc_preds_test[:, 1])\n",
    "print((a+b)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.     0.     0.     0.     0.    -0.75 ]\n",
      "  [ 0.     0.     0.     0.     0.    -0.656]\n",
      "  [ 0.     0.     0.     0.     0.    -4.605]]\n",
      "\n",
      " [[ 0.     0.     0.     0.     0.    -0.686]\n",
      "  [ 0.     0.     0.     0.     0.    -0.724]\n",
      "  [ 0.     0.     0.     0.     0.    -4.443]]\n",
      "\n",
      " [[ 0.     0.     0.     0.     0.    -1.378]\n",
      "  [ 0.     0.     0.     0.     0.    -0.297]\n",
      "  [ 0.     0.     0.     0.     0.    -4.605]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.     0.     0.     0.     0.    -1.266]\n",
      "  [ 0.     0.     0.     0.     0.    -0.364]\n",
      "  [ 0.     0.     0.     0.     0.    -3.769]]\n",
      "\n",
      " [[ 0.     0.     0.     0.     0.    -1.228]\n",
      "  [ 0.     0.     0.     0.     0.    -0.359]\n",
      "  [ 0.     0.     0.     0.     0.    -4.605]]\n",
      "\n",
      " [[ 0.     0.     0.     0.     0.    -1.355]\n",
      "  [ 0.     0.     0.     0.     0.    -0.31 ]\n",
      "  [ 0.     0.     0.     0.     0.    -4.605]]]\n"
     ]
    }
   ],
   "source": [
    "# Baseline - overfit to intercept\n",
    "N = X_train.shape[0]\n",
    "P = X_train.shape[1]\n",
    "T = vc_beta.shape[1]\n",
    "overfit = np.zeros((N, T, P))\n",
    "overfit[:, :, -1] = np.log(np.clip(Y_train, 0.01, 0.99))\n",
    "print(overfit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.    0.    0.    0.    0.    0.392]\n",
      "  [0.    0.    0.    0.    0.    0.597]\n",
      "  [0.    0.    0.    0.    0.    0.011]]\n",
      "\n",
      " [[0.    0.    0.    0.    0.    0.392]\n",
      "  [0.    0.    0.    0.    0.    0.597]\n",
      "  [0.    0.    0.    0.    0.    0.011]]\n",
      "\n",
      " [[0.    0.    0.    0.    0.    0.392]\n",
      "  [0.    0.    0.    0.    0.    0.597]\n",
      "  [0.    0.    0.    0.    0.    0.011]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.    0.    0.    0.    0.    0.392]\n",
      "  [0.    0.    0.    0.    0.    0.597]\n",
      "  [0.    0.    0.    0.    0.    0.011]]\n",
      "\n",
      " [[0.    0.    0.    0.    0.    0.392]\n",
      "  [0.    0.    0.    0.    0.    0.597]\n",
      "  [0.    0.    0.    0.    0.    0.011]]\n",
      "\n",
      " [[0.    0.    0.    0.    0.    0.392]\n",
      "  [0.    0.    0.    0.    0.    0.597]\n",
      "  [0.    0.    0.    0.    0.    0.011]]]\n"
     ]
    }
   ],
   "source": [
    "# Baseline - Mean\n",
    "base = np.zeros((N, 3, P))\n",
    "base[:, :, -1] = np.mean(Y_train, axis=0)  # TODO: Should this be log?\n",
    "print(base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <_io.FileIO name='/home/ben/.keras/keras.json' mode='rb'>\n",
      "ResourceWarning: unclosed file <_io.TextIOWrapper name='/home/ben/.keras/keras.json' mode='r' encoding='UTF-8'>\n"
     ]
    }
   ],
   "source": [
    "#### Deep Learning benchmark.\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"the matrix subclass is\")\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 25\n",
    "\n",
    "# Define a model with many linear regression atoms.\n",
    "def xavier_init(fan_in, fan_out, constant=1):\n",
    "    #Xavier initialization of network weights\n",
    "    low = -constant*np.sqrt(6.0/(fan_in + fan_out))\n",
    "    high = constant*np.sqrt(6.0/(fan_in + fan_out + 1))\n",
    "    return tf.random_uniform((fan_in, fan_out),\n",
    "                             minval=low, maxval=high,\n",
    "                             dtype=tf.float32)\n",
    "try:\n",
    "    tf.reset_default_graph()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "lr = 1e-4\n",
    "lr_decay = 1-1e-4\n",
    "learning_rate = tf.Variable(lr)\n",
    "\n",
    "X_shape = X_train.shape[1] + Z_train.shape[1]\n",
    "Y_shape = [3]\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, X_shape])\n",
    "y = tf.placeholder(tf.float32, [None, 3])\n",
    "\n",
    "n_hidden = [250, 250, 250, 250]\n",
    "eta_1 = tf.verify_tensor_all_finite(\n",
    "    tf.Variable(tf.random_uniform(\n",
    "        (X_shape, n_hidden[0]), minval=-1, maxval=1, dtype=tf.float32)),\n",
    "    'eta_1 not finite')\n",
    "b_1   = tf.Variable(tf.zeros([n_hidden[0]], dtype=tf.float32))\n",
    "eta_2 = tf.verify_tensor_all_finite(\n",
    "    tf.Variable(tf.random_uniform(\n",
    "        (n_hidden[0], n_hidden[1]), minval=-1, maxval=1, dtype=tf.float32)),\n",
    "    'eta_2 not finite')\n",
    "b_2   = tf.Variable(tf.zeros([n_hidden[1]], dtype=tf.float32))\n",
    "eta_3 = tf.verify_tensor_all_finite(\n",
    "    tf.Variable(tf.random_uniform(\n",
    "        (n_hidden[1], n_hidden[2]), minval=-1, maxval=1, dtype=tf.float32)),\n",
    "    'eta_3 not finite')\n",
    "b_3   = tf.Variable(tf.zeros(n_hidden[2], dtype=tf.float32))\n",
    "\n",
    "eta_4 = tf.verify_tensor_all_finite(\n",
    "    tf.Variable(tf.random_uniform(\n",
    "        (n_hidden[2], n_hidden[3]), minval=-1, maxval=1, dtype=tf.float32)),\n",
    "    'eta_4 not finite')\n",
    "b_4   = tf.Variable(tf.zeros(n_hidden[3], dtype=tf.float32))\n",
    "\n",
    "eta_5 = tf.verify_tensor_all_finite(\n",
    "    tf.Variable(tf.random_uniform(\n",
    "        (n_hidden[3], Y_shape[0]), minval=-1, maxval=1, dtype=tf.float32)),\n",
    "    'eta_5 not finite')\n",
    "b_5   = tf.Variable(tf.zeros(Y_shape, dtype=tf.float32))\n",
    "\n",
    "\n",
    "hidden_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, eta_1), b_1))\n",
    "hidden_2 = tf.nn.sigmoid(tf.add(tf.matmul(hidden_1, eta_2), b_2))\n",
    "hidden_3 = tf.nn.sigmoid(tf.add(tf.matmul(hidden_2, eta_3), b_3))\n",
    "hidden_4 = tf.nn.sigmoid(tf.add(tf.matmul(hidden_3, eta_4), b_4))\n",
    "y_hat  = tf.add(tf.matmul(hidden_4, eta_5), b_5)\n",
    "\n",
    "loss = tf.losses.mean_squared_error(y[:, 0], y_hat[:, 0]) + tf.losses.mean_squared_error(y[:, 1], y_hat[:, 1])\n",
    "loss += 1e-2*tf.add_n([tf.nn.l2_loss(v) for v in [eta_1, eta_2, eta_3, eta_4] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(\n",
    "    learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "try:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess = tf.InteractiveSession()\n",
    "    sess.run(init)\n",
    "except UserWarning:\n",
    "    sess.close()\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess = tf.InteractiveSession()\n",
    "    sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2135, 6)\n",
      "(2135, 8)\n",
      "0.0002\n",
      "0 27612.020874023438\n",
      "1 26864.06201171875\n",
      "2 26859.478759765625\n",
      "3 26854.92349243164\n",
      "4 26850.365112304688\n",
      "5 26845.791748046875\n",
      "6 26841.233001708984\n",
      "7 26836.662048339844\n",
      "8 26832.094207763672\n",
      "9 26827.53335571289\n",
      "10 26822.97378540039\n",
      "11 26818.41812133789\n",
      "12 26813.855194091797\n",
      "13 26809.292083740234\n",
      "14 26804.747100830078\n",
      "15 26800.154846191406\n",
      "16 26795.63330078125\n",
      "17 26791.077209472656\n",
      "18 26786.51040649414\n",
      "19 26781.963897705078\n",
      "20 26777.394317626953\n",
      "21 26772.855194091797\n",
      "22 26768.313201904297\n",
      "23 26763.74349975586\n",
      "24 26759.202697753906\n",
      "25 26754.663940429688\n",
      "26 26750.12030029297\n",
      "27 26745.56671142578\n",
      "28 26741.019317626953\n",
      "29 26736.47332763672\n",
      "30 26731.92694091797\n",
      "31 26727.37240600586\n",
      "32 26722.844604492188\n",
      "33 26718.308471679688\n",
      "34 26713.751403808594\n",
      "35 26709.200714111328\n",
      "36 26704.673065185547\n",
      "37 26700.14404296875\n",
      "38 26695.574096679688\n",
      "39 26691.062957763672\n",
      "40 26686.53692626953\n",
      "41 26681.9921875\n",
      "42 26677.46356201172\n",
      "43 26672.915802001953\n",
      "44 26668.380126953125\n",
      "45 26663.8486328125\n",
      "46 26659.319610595703\n",
      "47 26654.779724121094\n",
      "48 26650.25521850586\n",
      "49 26645.707763671875\n",
      "50 26641.190368652344\n",
      "51 26636.663848876953\n",
      "52 26632.135192871094\n",
      "53 26627.61312866211\n",
      "54 26623.077880859375\n",
      "55 26618.54623413086\n",
      "56 26614.019897460938\n",
      "57 26609.50912475586\n",
      "58 26604.95556640625\n",
      "59 26600.449768066406\n",
      "60 26595.9130859375\n",
      "61 26591.41943359375\n",
      "62 26586.896575927734\n",
      "63 26582.386260986328\n",
      "64 26577.856079101562\n",
      "65 26573.347534179688\n",
      "66 26568.84017944336\n",
      "67 26564.300201416016\n",
      "68 26559.798370361328\n",
      "69 26555.277770996094\n",
      "70 26550.774353027344\n",
      "71 26546.255310058594\n",
      "72 26541.726623535156\n",
      "73 26537.240997314453\n",
      "74 26532.7314453125\n",
      "75 26528.21795654297\n",
      "76 26523.709869384766\n",
      "77 26519.19985961914\n",
      "78 26514.673278808594\n",
      "79 26510.17855834961\n",
      "80 26505.669036865234\n",
      "81 26501.171783447266\n",
      "82 26496.666748046875\n",
      "83 26492.15802001953\n",
      "84 26487.66925048828\n",
      "85 26483.159881591797\n",
      "86 26478.653289794922\n",
      "87 26474.166015625\n",
      "88 26469.64697265625\n",
      "89 26465.162384033203\n",
      "90 26460.67300415039\n",
      "91 26456.160034179688\n",
      "92 26451.662170410156\n",
      "93 26447.175811767578\n",
      "94 26442.673858642578\n",
      "95 26438.193267822266\n",
      "96 26433.67398071289\n",
      "97 26429.193481445312\n",
      "98 26424.703338623047\n",
      "99 26420.214721679688\n",
      "100 26415.710968017578\n",
      "101 26411.235717773438\n",
      "102 26406.744079589844\n",
      "103 26402.258666992188\n",
      "104 26397.767120361328\n",
      "105 26393.275146484375\n",
      "106 26388.801055908203\n",
      "107 26384.31072998047\n",
      "108 26379.826538085938\n",
      "109 26375.343719482422\n",
      "110 26370.840698242188\n",
      "111 26366.385528564453\n",
      "112 26361.891357421875\n",
      "113 26357.42056274414\n",
      "114 26352.94659423828\n",
      "115 26348.451599121094\n",
      "116 26343.98956298828\n",
      "117 26339.514526367188\n",
      "118 26335.040618896484\n",
      "119 26330.562774658203\n",
      "120 26326.087005615234\n",
      "121 26321.619659423828\n",
      "122 26317.145263671875\n",
      "123 26312.657989501953\n",
      "124 26308.185028076172\n",
      "125 26303.71356201172\n",
      "126 26299.249450683594\n",
      "127 26294.776641845703\n",
      "128 26290.326232910156\n",
      "129 26285.83578491211\n",
      "130 26281.365600585938\n",
      "131 26276.906005859375\n",
      "132 26272.444580078125\n",
      "133 26267.960845947266\n",
      "134 26263.538055419922\n",
      "135 26259.061950683594\n",
      "136 26254.58853149414\n",
      "137 26250.129486083984\n",
      "138 26245.681701660156\n",
      "139 26241.209991455078\n",
      "140 26236.75454711914\n",
      "141 26232.309112548828\n",
      "142 26227.83187866211\n",
      "143 26223.38491821289\n",
      "144 26218.922393798828\n",
      "145 26214.463958740234\n",
      "146 26210.02783203125\n",
      "147 26205.540802001953\n",
      "148 26201.103973388672\n",
      "149 26196.65411376953\n",
      "150 26192.208740234375\n",
      "151 26187.748748779297\n",
      "152 26183.294921875\n",
      "153 26178.84228515625\n",
      "154 26174.418487548828\n",
      "155 26169.953491210938\n",
      "156 26165.510192871094\n",
      "157 26161.066162109375\n",
      "158 26156.622497558594\n",
      "159 26152.18048095703\n",
      "160 26147.736877441406\n",
      "161 26143.295928955078\n",
      "162 26138.852142333984\n",
      "163 26134.409271240234\n",
      "164 26129.94320678711\n",
      "165 26125.518951416016\n",
      "166 26121.082977294922\n",
      "167 26116.646881103516\n",
      "168 26112.19842529297\n",
      "169 26107.7724609375\n",
      "170 26103.3603515625\n",
      "171 26098.89779663086\n",
      "172 26094.473693847656\n",
      "173 26090.053466796875\n",
      "174 26085.601959228516\n",
      "175 26081.182556152344\n",
      "176 26076.73779296875\n",
      "177 26072.313415527344\n",
      "178 26067.874389648438\n",
      "179 26063.469482421875\n",
      "180 26059.037231445312\n",
      "181 26054.602661132812\n",
      "182 26050.18359375\n",
      "183 26045.75405883789\n",
      "184 26041.337829589844\n",
      "185 26036.891387939453\n",
      "186 26032.483917236328\n",
      "187 26028.057220458984\n",
      "188 26023.628479003906\n",
      "189 26019.208526611328\n",
      "190 26014.81185913086\n",
      "191 26010.37469482422\n",
      "192 26005.959899902344\n",
      "193 26001.531982421875\n",
      "194 25997.122283935547\n",
      "195 25992.69744873047\n",
      "196 25988.284149169922\n",
      "197 25983.86279296875\n",
      "198 25979.45654296875\n",
      "199 25975.043365478516\n",
      "200 25970.63345336914\n",
      "201 25966.222290039062\n",
      "202 25961.80419921875\n",
      "203 25957.40219116211\n",
      "204 25952.98309326172\n",
      "205 25948.580139160156\n",
      "206 25944.17547607422\n",
      "207 25939.768524169922\n",
      "208 25935.35516357422\n",
      "209 25930.952850341797\n",
      "210 25926.537384033203\n",
      "211 25922.13851928711\n",
      "212 25917.723999023438\n",
      "213 25913.345489501953\n",
      "214 25908.935180664062\n",
      "215 25904.52850341797\n",
      "216 25900.137756347656\n",
      "217 25895.716247558594\n",
      "218 25891.325073242188\n",
      "219 25886.943786621094\n",
      "220 25882.531219482422\n",
      "221 25878.129333496094\n",
      "222 25873.736755371094\n",
      "223 25869.34765625\n",
      "224 25864.94024658203\n",
      "225 25860.552612304688\n",
      "226 25856.146270751953\n",
      "227 25851.77182006836\n",
      "228 25847.362518310547\n",
      "229 25842.983154296875\n",
      "230 25838.573516845703\n",
      "231 25834.201080322266\n",
      "232 25829.806213378906\n",
      "233 25825.41146850586\n",
      "234 25821.035186767578\n",
      "235 25816.639282226562\n",
      "236 25812.24932861328\n",
      "237 25807.856079101562\n",
      "238 25803.488159179688\n",
      "239 25799.08819580078\n",
      "240 25794.734588623047\n",
      "241 25790.32354736328\n",
      "242 25785.94940185547\n",
      "243 25781.576538085938\n",
      "244 25777.191497802734\n",
      "245 25772.811431884766\n",
      "246 25768.431213378906\n",
      "247 25764.03546142578\n",
      "248 25759.67025756836\n",
      "249 25755.294403076172\n",
      "250 25750.930267333984\n",
      "251 25746.542022705078\n",
      "252 25742.165924072266\n",
      "253 25737.80795288086\n",
      "254 25733.428131103516\n",
      "255 25729.0634765625\n",
      "256 25724.693725585938\n",
      "257 25720.316162109375\n",
      "258 25715.955993652344\n",
      "259 25711.576080322266\n",
      "260 25707.212646484375\n",
      "261 25702.837463378906\n",
      "262 25698.47576904297\n",
      "263 25694.121368408203\n",
      "264 25689.743927001953\n",
      "265 25685.377655029297\n",
      "266 25681.007080078125\n",
      "267 25676.651947021484\n",
      "268 25672.305786132812\n",
      "269 25667.934783935547\n",
      "270 25663.566619873047\n",
      "271 25659.204711914062\n",
      "272 25654.853118896484\n",
      "273 25650.492553710938\n",
      "274 25646.136199951172\n",
      "275 25641.7666015625\n",
      "276 25637.4052734375\n",
      "277 25633.056365966797\n",
      "278 25628.696350097656\n",
      "279 25624.329681396484\n",
      "280 25619.986236572266\n",
      "281 25615.633544921875\n",
      "282 25611.29034423828\n",
      "283 25606.927856445312\n",
      "284 25602.58578491211\n",
      "285 25598.244201660156\n",
      "286 25593.887145996094\n",
      "287 25589.531860351562\n",
      "288 25585.208862304688\n",
      "289 25580.85971069336\n",
      "290 25576.497161865234\n",
      "291 25572.1435546875\n",
      "292 25567.799530029297\n",
      "293 25563.460083007812\n",
      "294 25559.112762451172\n",
      "295 25554.772583007812\n",
      "296 25550.419525146484\n",
      "297 25546.085388183594\n",
      "298 25541.75372314453\n",
      "299 25537.400482177734\n",
      "300 25533.081634521484\n",
      "301 25528.735717773438\n",
      "302 25524.378051757812\n",
      "303 25520.045196533203\n",
      "304 25515.713134765625\n",
      "305 25511.367736816406\n",
      "306 25507.030334472656\n",
      "307 25502.70281982422\n",
      "308 25498.366088867188\n",
      "309 25494.03045654297\n",
      "310 25489.697631835938\n",
      "311 25485.380004882812\n",
      "312 25481.029754638672\n",
      "313 25476.725708007812\n",
      "314 25472.384002685547\n",
      "315 25468.074249267578\n",
      "316 25463.735809326172\n",
      "317 25459.405059814453\n",
      "318 25455.087127685547\n",
      "319 25450.763549804688\n",
      "320 25446.436981201172\n",
      "321 25442.111419677734\n",
      "322 25437.788787841797\n",
      "323 25433.46563720703\n",
      "324 25429.148559570312\n",
      "325 25424.83120727539\n",
      "326 25420.497344970703\n",
      "327 25416.17694091797\n",
      "328 25411.857482910156\n",
      "329 25407.541870117188\n",
      "330 25403.230743408203\n",
      "331 25398.907745361328\n",
      "332 25394.594696044922\n",
      "333 25390.273376464844\n",
      "334 25385.96661376953\n",
      "335 25381.649658203125\n",
      "336 25377.334106445312\n",
      "337 25373.01885986328\n",
      "338 25368.714447021484\n",
      "339 25364.388610839844\n",
      "340 25360.09405517578\n",
      "341 25355.791015625\n",
      "342 25351.479858398438\n",
      "343 25347.168365478516\n",
      "344 25342.85433959961\n",
      "345 25338.5595703125\n",
      "346 25334.2333984375\n",
      "347 25329.93505859375\n",
      "348 25325.63998413086\n",
      "349 25321.335723876953\n",
      "350 25317.02911376953\n",
      "351 25312.71810913086\n",
      "352 25308.42120361328\n",
      "353 25304.128540039062\n",
      "354 25299.83416748047\n",
      "355 25295.508422851562\n",
      "356 25291.223876953125\n",
      "357 25286.94076538086\n",
      "358 25282.63638305664\n",
      "359 25278.32080078125\n",
      "360 25274.04428100586\n",
      "361 25269.756713867188\n",
      "362 25265.462463378906\n",
      "363 25261.167114257812\n",
      "364 25256.871154785156\n",
      "365 25252.575714111328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "366 25248.289459228516\n",
      "367 25244.006439208984\n",
      "368 25239.713500976562\n",
      "369 25235.417205810547\n",
      "370 25231.12777709961\n",
      "371 25226.843231201172\n",
      "372 25222.553771972656\n",
      "373 25218.264190673828\n",
      "374 25213.9716796875\n",
      "375 25209.678619384766\n",
      "376 25205.393524169922\n",
      "377 25201.130828857422\n",
      "378 25196.853942871094\n",
      "379 25192.558135986328\n",
      "380 25188.266998291016\n",
      "381 25184.012664794922\n",
      "382 25179.713470458984\n",
      "383 25175.432983398438\n",
      "384 25171.144989013672\n",
      "385 25166.885681152344\n",
      "386 25162.61376953125\n",
      "387 25158.34423828125\n",
      "388 25154.051971435547\n",
      "389 25149.77554321289\n",
      "390 25145.504119873047\n",
      "391 25141.237335205078\n",
      "392 25136.963104248047\n",
      "393 25132.69744873047\n",
      "394 25128.41421508789\n",
      "395 25124.153747558594\n",
      "396 25119.877716064453\n",
      "397 25115.622192382812\n",
      "398 25111.358123779297\n",
      "399 25107.08514404297\n",
      "400 25102.82681274414\n",
      "401 25098.54278564453\n",
      "402 25094.273681640625\n",
      "403 25090.021911621094\n",
      "404 25085.743774414062\n",
      "405 25081.483947753906\n",
      "406 25077.21762084961\n",
      "407 25072.964141845703\n",
      "408 25068.703094482422\n",
      "409 25064.435913085938\n",
      "410 25060.182983398438\n",
      "411 25055.92657470703\n",
      "412 25051.668884277344\n",
      "413 25047.406799316406\n",
      "414 25043.158813476562\n",
      "415 25038.887329101562\n",
      "416 25034.6328125\n",
      "417 25030.385284423828\n",
      "418 25026.13787841797\n",
      "419 25021.88394165039\n",
      "420 25017.632415771484\n",
      "421 25013.379608154297\n",
      "422 25009.11749267578\n",
      "423 25004.868377685547\n",
      "424 25000.619140625\n",
      "425 24996.386291503906\n",
      "426 24992.137634277344\n",
      "427 24987.872009277344\n",
      "428 24983.62176513672\n",
      "429 24979.396697998047\n",
      "430 24975.133209228516\n",
      "431 24970.90509033203\n",
      "432 24966.65155029297\n",
      "433 24962.416107177734\n",
      "434 24958.162567138672\n",
      "435 24953.934631347656\n",
      "436 24949.69009399414\n",
      "437 24945.433837890625\n",
      "438 24941.200592041016\n",
      "439 24936.96026611328\n",
      "440 24932.726776123047\n",
      "441 24928.485260009766\n",
      "442 24924.248992919922\n",
      "443 24920.009735107422\n",
      "444 24915.78302001953\n",
      "445 24911.564880371094\n",
      "446 24907.32241821289\n",
      "447 24903.090728759766\n",
      "448 24898.859985351562\n",
      "449 24894.62078857422\n",
      "450 24890.37924194336\n",
      "451 24886.148406982422\n",
      "452 24881.93081665039\n",
      "453 24877.698272705078\n",
      "454 24873.462036132812\n",
      "455 24869.2060546875\n",
      "456 24865.035064697266\n",
      "457 24860.78546142578\n",
      "458 24856.554809570312\n",
      "459 24852.337677001953\n",
      "460 24848.12176513672\n",
      "461 24843.883270263672\n",
      "462 24839.682525634766\n",
      "463 24835.445098876953\n",
      "464 24831.232391357422\n",
      "465 24826.997589111328\n",
      "466 24822.777374267578\n",
      "467 24818.56039428711\n",
      "468 24814.34698486328\n",
      "469 24810.117706298828\n",
      "470 24805.903411865234\n",
      "471 24801.68719482422\n",
      "472 24797.47833251953\n",
      "473 24793.273864746094\n",
      "474 24789.059814453125\n",
      "475 24784.829650878906\n",
      "476 24780.620880126953\n",
      "477 24776.429321289062\n",
      "478 24772.203857421875\n",
      "479 24767.992126464844\n",
      "480 24763.784210205078\n",
      "481 24759.582092285156\n",
      "482 24755.385681152344\n",
      "483 24751.16683959961\n",
      "484 24746.95425415039\n",
      "485 24742.74737548828\n",
      "486 24738.548583984375\n",
      "487 24734.333770751953\n",
      "488 24730.126495361328\n",
      "489 24725.930603027344\n",
      "490 24721.734008789062\n",
      "491 24717.508819580078\n",
      "492 24713.327545166016\n",
      "493 24709.119750976562\n",
      "494 24704.927154541016\n",
      "495 24700.731018066406\n",
      "496 24696.509307861328\n",
      "497 24692.313690185547\n",
      "498 24688.12042236328\n",
      "499 24683.929595947266\n",
      "500 24679.724731445312\n",
      "501 24675.551971435547\n",
      "502 24671.371032714844\n",
      "503 24667.174591064453\n",
      "504 24662.981170654297\n",
      "505 24658.78109741211\n",
      "506 24654.595306396484\n",
      "507 24650.40689086914\n",
      "508 24646.206604003906\n",
      "509 24642.001983642578\n",
      "510 24637.833587646484\n",
      "511 24633.631439208984\n",
      "512 24629.44580078125\n",
      "513 24625.26727294922\n",
      "514 24621.091888427734\n",
      "515 24616.894134521484\n",
      "516 24612.69253540039\n",
      "517 24608.53192138672\n",
      "518 24604.354461669922\n",
      "519 24600.16177368164\n",
      "520 24595.982299804688\n",
      "521 24591.79364013672\n",
      "522 24587.612731933594\n",
      "523 24583.436950683594\n",
      "524 24579.273956298828\n",
      "525 24575.08480834961\n",
      "526 24570.904571533203\n",
      "527 24566.739654541016\n",
      "528 24562.552337646484\n",
      "529 24558.380859375\n",
      "530 24554.219116210938\n",
      "531 24550.02865600586\n",
      "532 24545.86395263672\n",
      "533 24541.691375732422\n",
      "534 24537.498931884766\n",
      "535 24533.351013183594\n",
      "536 24529.17791748047\n",
      "537 24524.999633789062\n",
      "538 24520.841918945312\n",
      "539 24516.678009033203\n",
      "540 24512.498809814453\n",
      "541 24508.33087158203\n",
      "542 24504.173461914062\n",
      "543 24500.00375366211\n",
      "544 24495.84359741211\n",
      "545 24491.655883789062\n",
      "546 24487.52947998047\n",
      "547 24483.357788085938\n",
      "548 24479.189849853516\n",
      "549 24475.031677246094\n",
      "550 24470.865295410156\n",
      "551 24466.71905517578\n",
      "552 24462.550750732422\n",
      "553 24458.388061523438\n",
      "554 24454.240325927734\n",
      "555 24450.058654785156\n",
      "556 24445.90707397461\n",
      "557 24441.76727294922\n",
      "558 24437.614654541016\n",
      "559 24433.444244384766\n",
      "560 24429.29409790039\n",
      "561 24425.162353515625\n",
      "562 24420.999267578125\n",
      "563 24416.85546875\n",
      "564 24412.711700439453\n",
      "565 24408.53939819336\n",
      "566 24404.40557861328\n",
      "567 24400.257232666016\n",
      "568 24396.10971069336\n",
      "569 24391.958709716797\n",
      "570 24387.836181640625\n",
      "571 24383.690399169922\n",
      "572 24379.529724121094\n",
      "573 24375.38250732422\n",
      "574 24371.246612548828\n",
      "575 24367.056610107422\n",
      "576 24362.957397460938\n",
      "577 24358.839477539062\n",
      "578 24354.687896728516\n",
      "579 24350.524688720703\n",
      "580 24346.379669189453\n",
      "581 24342.238311767578\n",
      "582 24338.129760742188\n",
      "583 24333.984283447266\n",
      "584 24329.84832763672\n",
      "585 24325.72442626953\n",
      "586 24321.58218383789\n",
      "587 24317.428588867188\n",
      "588 24313.327667236328\n",
      "589 24309.192016601562\n",
      "590 24305.034301757812\n",
      "591 24300.92156982422\n",
      "592 24296.773315429688\n",
      "593 24292.66925048828\n",
      "594 24288.525299072266\n",
      "595 24284.40155029297\n",
      "596 24280.274688720703\n",
      "597 24276.156372070312\n",
      "598 24272.015869140625\n",
      "599 24267.90087890625\n",
      "600 24263.776458740234\n",
      "601 24259.649963378906\n",
      "602 24255.51593017578\n",
      "603 24251.41619873047\n",
      "604 24247.276977539062\n",
      "605 24243.17123413086\n",
      "606 24239.04214477539\n",
      "607 24234.924285888672\n",
      "608 24230.812774658203\n",
      "609 24226.68914794922\n",
      "610 24222.57241821289\n",
      "611 24218.456573486328\n",
      "612 24214.325164794922\n",
      "613 24210.218627929688\n",
      "614 24206.091552734375\n",
      "615 24201.985748291016\n",
      "616 24197.88363647461\n",
      "617 24193.75018310547\n",
      "618 24189.637237548828\n",
      "619 24185.531707763672\n",
      "620 24181.40802001953\n",
      "621 24177.307342529297\n",
      "622 24173.21664428711\n",
      "623 24169.093200683594\n",
      "624 24164.99105834961\n",
      "625 24160.869659423828\n",
      "626 24156.78305053711\n",
      "627 24152.685791015625\n",
      "628 24148.58657836914\n",
      "629 24144.455780029297\n",
      "630 24140.35137939453\n",
      "631 24136.26480102539\n",
      "632 24132.146881103516\n",
      "633 24128.06381225586\n",
      "634 24123.949432373047\n",
      "635 24119.863891601562\n",
      "636 24115.763671875\n",
      "637 24111.657592773438\n",
      "638 24107.55682373047\n",
      "639 24103.43930053711\n",
      "640 24099.336334228516\n",
      "641 24095.27374267578\n",
      "642 24091.184356689453\n",
      "643 24087.081787109375\n",
      "644 24082.990783691406\n",
      "645 24078.89080810547\n",
      "646 24074.804321289062\n",
      "647 24070.701782226562\n",
      "648 24066.615783691406\n",
      "649 24062.526916503906\n",
      "650 24058.443237304688\n",
      "651 24054.34146118164\n",
      "652 24050.247589111328\n",
      "653 24046.154296875\n",
      "654 24042.084533691406\n",
      "655 24037.98794555664\n",
      "656 24033.906005859375\n",
      "657 24029.820220947266\n",
      "658 24025.738342285156\n",
      "659 24021.659271240234\n",
      "660 24017.570556640625\n",
      "661 24013.49545288086\n",
      "662 24009.42694091797\n",
      "663 24005.333709716797\n",
      "664 24001.23846435547\n",
      "665 23997.165588378906\n",
      "666 23993.104278564453\n",
      "667 23989.00860595703\n",
      "668 23984.938598632812\n",
      "669 23980.86312866211\n",
      "670 23976.795837402344\n",
      "671 23972.712310791016\n",
      "672 23968.620574951172\n",
      "673 23964.56365966797\n",
      "674 23960.482696533203\n",
      "675 23956.382293701172\n",
      "676 23952.342742919922\n",
      "677 23948.245056152344\n",
      "678 23944.178833007812\n",
      "679 23940.121490478516\n",
      "680 23936.06332397461\n",
      "681 23931.9912109375\n",
      "682 23927.93292236328\n",
      "683 23923.87530517578\n",
      "684 23919.80487060547\n",
      "685 23915.71987915039\n",
      "686 23911.669952392578\n",
      "687 23907.582611083984\n",
      "688 23903.532592773438\n",
      "689 23899.48764038086\n",
      "690 23895.422760009766\n",
      "691 23891.348358154297\n",
      "692 23887.304168701172\n",
      "693 23883.219451904297\n",
      "694 23879.150970458984\n",
      "695 23875.121948242188\n",
      "696 23871.058471679688\n",
      "697 23866.994750976562\n",
      "698 23862.943756103516\n",
      "699 23858.88995361328\n",
      "700 23854.825897216797\n",
      "701 23850.77261352539\n",
      "702 23846.69888305664\n",
      "703 23842.660705566406\n",
      "704 23838.620147705078\n",
      "705 23834.5517578125\n",
      "706 23830.504760742188\n",
      "707 23826.464599609375\n",
      "708 23822.392364501953\n",
      "709 23818.356323242188\n",
      "710 23814.309112548828\n",
      "711 23810.27816772461\n",
      "712 23806.20721435547\n",
      "713 23802.167053222656\n",
      "714 23798.107635498047\n",
      "715 23794.06576538086\n",
      "716 23790.043823242188\n",
      "717 23785.999145507812\n",
      "718 23781.946990966797\n",
      "719 23777.907836914062\n",
      "720 23773.871948242188\n",
      "721 23769.824676513672\n",
      "722 23765.77719116211\n",
      "723 23761.75064086914\n",
      "724 23757.712371826172\n",
      "725 23753.672637939453\n",
      "726 23749.62826538086\n",
      "727 23745.59051513672\n",
      "728 23741.548736572266\n",
      "729 23737.514526367188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "730 23733.494689941406\n",
      "731 23729.452087402344\n",
      "732 23725.39810180664\n",
      "733 23721.370971679688\n",
      "734 23717.34649658203\n",
      "735 23713.32763671875\n",
      "736 23709.301879882812\n",
      "737 23705.268432617188\n",
      "738 23701.24346923828\n",
      "739 23697.211486816406\n",
      "740 23693.18685913086\n",
      "741 23689.16421508789\n",
      "742 23685.14047241211\n",
      "743 23681.108123779297\n",
      "744 23677.068786621094\n",
      "745 23673.057067871094\n",
      "746 23669.03970336914\n",
      "747 23665.020904541016\n",
      "748 23660.980102539062\n",
      "749 23656.972717285156\n",
      "750 23652.943237304688\n",
      "751 23648.927459716797\n",
      "752 23644.903900146484\n",
      "753 23640.89535522461\n",
      "754 23636.864471435547\n",
      "755 23632.84878540039\n",
      "756 23628.841766357422\n",
      "757 23624.826538085938\n",
      "758 23620.809631347656\n",
      "759 23616.789794921875\n",
      "760 23612.790252685547\n",
      "761 23608.77374267578\n",
      "762 23604.763549804688\n",
      "763 23600.739379882812\n",
      "764 23596.714965820312\n",
      "765 23592.706146240234\n",
      "766 23588.703979492188\n",
      "767 23584.70166015625\n",
      "768 23580.696166992188\n",
      "769 23576.69171142578\n",
      "770 23572.677032470703\n",
      "771 23568.679809570312\n",
      "772 23564.677856445312\n",
      "773 23560.64453125\n",
      "774 23556.659545898438\n",
      "775 23552.64129638672\n",
      "776 23548.64614868164\n",
      "777 23544.640899658203\n",
      "778 23540.648376464844\n",
      "779 23536.669555664062\n",
      "780 23532.633361816406\n",
      "781 23528.66241455078\n",
      "782 23524.655487060547\n",
      "783 23520.66177368164\n",
      "784 23516.65606689453\n",
      "785 23512.658935546875\n",
      "786 23508.670318603516\n",
      "787 23504.685607910156\n",
      "788 23500.679168701172\n",
      "789 23496.691986083984\n",
      "790 23492.68911743164\n",
      "791 23488.695220947266\n",
      "792 23484.694061279297\n",
      "793 23480.694427490234\n",
      "794 23476.733032226562\n",
      "795 23472.725311279297\n",
      "796 23468.737243652344\n",
      "797 23464.761169433594\n",
      "798 23460.759490966797\n",
      "799 23456.78173828125\n",
      "800 23452.796997070312\n",
      "801 23448.814453125\n",
      "802 23444.826049804688\n",
      "803 23440.837310791016\n",
      "804 23436.84503173828\n",
      "805 23432.868591308594\n",
      "806 23428.890167236328\n",
      "807 23424.92156982422\n",
      "808 23420.93099975586\n",
      "809 23416.94268798828\n",
      "810 23412.95278930664\n",
      "811 23408.984313964844\n",
      "812 23405.02081298828\n",
      "813 23401.046020507812\n",
      "814 23397.062408447266\n",
      "815 23393.063903808594\n",
      "816 23389.116912841797\n",
      "817 23385.151733398438\n",
      "818 23381.17498779297\n",
      "819 23377.171356201172\n",
      "820 23373.201202392578\n",
      "821 23369.23944091797\n",
      "822 23365.266082763672\n",
      "823 23361.307983398438\n",
      "824 23357.32647705078\n",
      "825 23353.36163330078\n",
      "826 23349.390899658203\n",
      "827 23345.422973632812\n",
      "828 23341.456665039062\n",
      "829 23337.496459960938\n",
      "830 23333.51318359375\n",
      "831 23329.56118774414\n",
      "832 23325.61068725586\n",
      "833 23321.648559570312\n",
      "834 23317.6787109375\n",
      "835 23313.685424804688\n",
      "836 23309.74200439453\n",
      "837 23305.78289794922\n",
      "838 23301.81625366211\n",
      "839 23297.864013671875\n",
      "840 23293.907165527344\n",
      "841 23289.94708251953\n",
      "842 23285.99526977539\n",
      "843 23282.02798461914\n",
      "844 23278.089447021484\n",
      "845 23274.120361328125\n",
      "846 23270.16781616211\n",
      "847 23266.220581054688\n",
      "848 23262.23095703125\n",
      "849 23258.303161621094\n",
      "850 23254.35223388672\n",
      "851 23250.398834228516\n",
      "852 23246.425994873047\n",
      "853 23242.516357421875\n",
      "854 23238.546905517578\n",
      "855 23234.616149902344\n",
      "856 23230.640228271484\n",
      "857 23226.710235595703\n",
      "858 23222.757354736328\n",
      "859 23218.814392089844\n",
      "860 23214.849884033203\n",
      "861 23210.930908203125\n",
      "862 23206.97674560547\n",
      "863 23203.03842163086\n",
      "864 23199.096069335938\n",
      "865 23195.147399902344\n",
      "866 23191.203704833984\n",
      "867 23187.263793945312\n",
      "868 23183.33135986328\n",
      "869 23179.387481689453\n",
      "870 23175.443725585938\n",
      "871 23171.524810791016\n",
      "872 23167.57470703125\n",
      "873 23163.634826660156\n",
      "874 23159.71368408203\n",
      "875 23155.768005371094\n",
      "876 23151.836456298828\n",
      "877 23147.906982421875\n",
      "878 23143.97625732422\n",
      "879 23140.038330078125\n",
      "880 23136.110290527344\n",
      "881 23132.175506591797\n",
      "882 23128.236083984375\n",
      "883 23124.328521728516\n",
      "884 23120.384887695312\n",
      "885 23116.46224975586\n",
      "886 23112.5341796875\n",
      "887 23108.6015625\n",
      "888 23104.666107177734\n",
      "889 23100.742431640625\n",
      "890 23096.832275390625\n",
      "891 23092.89584350586\n",
      "892 23088.991760253906\n",
      "893 23085.060943603516\n",
      "894 23081.13885498047\n",
      "895 23077.204193115234\n",
      "896 23073.29541015625\n",
      "897 23069.364227294922\n",
      "898 23065.45001220703\n",
      "899 23061.523712158203\n",
      "900 23057.618713378906\n",
      "901 23053.699005126953\n",
      "902 23049.78076171875\n",
      "903 23045.870819091797\n",
      "904 23041.947021484375\n",
      "905 23038.02505493164\n",
      "906 23034.12774658203\n",
      "907 23030.198303222656\n",
      "908 23026.279998779297\n",
      "909 23022.377227783203\n",
      "910 23018.446197509766\n",
      "911 23014.56005859375\n",
      "912 23010.655639648438\n",
      "913 23006.73794555664\n",
      "914 23002.838012695312\n",
      "915 22998.931671142578\n",
      "916 22995.022186279297\n",
      "917 22991.11703491211\n",
      "918 22987.202667236328\n",
      "919 22983.29214477539\n",
      "920 22979.390563964844\n",
      "921 22975.495819091797\n",
      "922 22971.583740234375\n",
      "923 22967.68637084961\n",
      "924 22963.780548095703\n",
      "925 22959.869232177734\n",
      "926 22955.981536865234\n",
      "927 22952.080505371094\n",
      "928 22948.158905029297\n",
      "929 22944.288787841797\n",
      "930 22940.376892089844\n",
      "931 22936.487670898438\n",
      "932 22932.601531982422\n",
      "933 22928.698333740234\n",
      "934 22924.804901123047\n",
      "935 22920.90103149414\n",
      "936 22917.014678955078\n",
      "937 22913.11737060547\n",
      "938 22909.21841430664\n",
      "939 22905.330474853516\n",
      "940 22901.444793701172\n",
      "941 22897.5615234375\n",
      "942 22893.650115966797\n",
      "943 22889.782287597656\n",
      "944 22885.89190673828\n",
      "945 22881.99984741211\n",
      "946 22878.105682373047\n",
      "947 22874.2197265625\n",
      "948 22870.31216430664\n",
      "949 22866.450103759766\n",
      "950 22862.563110351562\n",
      "951 22858.690368652344\n",
      "952 22854.795013427734\n",
      "953 22850.900268554688\n",
      "954 22847.015228271484\n",
      "955 22843.157104492188\n",
      "956 22839.263885498047\n",
      "957 22835.394012451172\n",
      "958 22831.51498413086\n",
      "959 22827.628875732422\n",
      "960 22823.75762939453\n",
      "961 22819.865600585938\n",
      "962 22815.986877441406\n",
      "963 22812.12823486328\n",
      "964 22808.25210571289\n",
      "965 22804.380279541016\n",
      "966 22800.512481689453\n",
      "967 22796.633087158203\n",
      "968 22792.748016357422\n",
      "969 22788.888061523438\n",
      "970 22785.000091552734\n",
      "971 22781.13980102539\n",
      "972 22777.27719116211\n",
      "973 22773.410919189453\n",
      "974 22769.536560058594\n",
      "975 22765.64715576172\n",
      "976 22761.79443359375\n",
      "977 22757.910522460938\n",
      "978 22754.051696777344\n",
      "979 22750.199829101562\n",
      "980 22746.334930419922\n",
      "981 22742.47119140625\n",
      "982 22738.58969116211\n",
      "983 22734.730224609375\n",
      "984 22730.878143310547\n",
      "985 22727.001495361328\n",
      "986 22723.13037109375\n",
      "987 22719.288055419922\n",
      "988 22715.43603515625\n",
      "989 22711.57046508789\n",
      "990 22707.695068359375\n",
      "991 22703.85467529297\n",
      "992 22699.976928710938\n",
      "993 22696.142944335938\n",
      "994 22692.271484375\n",
      "995 22688.425720214844\n",
      "996 22684.55160522461\n",
      "997 22680.725311279297\n",
      "998 22676.873504638672\n",
      "999 22673.011260986328\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "XZ_train = np.hstack((X_train, Z_train))\n",
    "print(X_train.shape)\n",
    "print(XZ_train.shape)\n",
    "learning_rate *= 2\n",
    "print(sess.run((learning_rate)))\n",
    "for i in range(n_epochs):\n",
    "    learning_rate *= lr_decay\n",
    "    permutation = np.random.permutation(len(X_train))\n",
    "    total_cost = 0\n",
    "    for idx in range(0, len(X_train)-batch_size, batch_size):\n",
    "        start = idx\n",
    "        end = idx + batch_size\n",
    "        opt, cost, y_hat_val, eta_1_val = sess.run((optimizer, loss, y_hat, eta_1),\n",
    "                                       feed_dict={\n",
    "                                           x: XZ_train[permutation[start:end]],\n",
    "                                           y: Y_train[permutation[start:end]]\n",
    "                                       })\n",
    "        total_cost += cost\n",
    "        #print(y_hat_val, eta_1_val)#, Y_train[permutation[start:end]])\n",
    "    print(i, total_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_deep = sess.run((y_hat),\n",
    "                           feed_dict={\n",
    "                               x: np.hstack((X_train, Z_train))\n",
    "                           })\n",
    "\n",
    "test_predictions_deep = sess.run((y_hat),\n",
    "                           feed_dict={\n",
    "                               x: np.hstack((X_test, Z_test))\n",
    "                           })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.021206223393398168 0.02047413703660869 0.02084018021500343\n",
      "0.01913818530305638\n",
      "0.0040428552072387935\n"
     ]
    }
   ],
   "source": [
    "a = mean_squared_error(Y_train[:, 0], predictions_deep[:, 0])\n",
    "b = mean_squared_error(Y_train[:, 1], predictions_deep[:, 1])\n",
    "print(a, b, (a+b)/2)\n",
    "\n",
    "a = mean_squared_error(Y_test[:, 0], test_predictions_deep[:, 0])\n",
    "b = mean_squared_error(Y_test[:, 1], test_predictions_deep[:, 1])\n",
    "print((a+b)/2)\n",
    "\n",
    "a = r2_score(Y_test[:, 0], test_predictions_deep[:, 0])\n",
    "b = r2_score(Y_test[:, 1], test_predictions_deep[:, 1])\n",
    "print((a+b)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "T = 3\n",
    "P = 6\n",
    "beta_target = np.zeros((N_train, T, P))\n",
    "init_beta = np.zeros_like(beta_target)#vc_beta[:N, :P]\n",
    "\n",
    "lam = 1e-3\n",
    "gamma = 1e3\n",
    "alpha = 1e0\n",
    "upsilon = 1e-2\n",
    "inter_penalty = 0#2e0\n",
    "l2_ratio = 1.0\n",
    "rho_beta = lambda beta, i: lam*(functions.lasso_penalty(beta, beta_target[i])\n",
    "                                + l2_ratio*functions.l2_penalty(beta, beta_target[i])\n",
    "                               + inter_penalty*(beta[-1]**2))\n",
    "rho_beta_prime = lambda beta, i:lam*(functions.lasso_derivative(beta, beta_target[i])\n",
    "                                     + l2_ratio*functions.l2_prime(beta, beta_target[i])\n",
    "                                    + 2*inter_penalty*np.vstack((np.zeros_like(beta[:-1]), beta[-1])))\n",
    "\n",
    "init_phi_beta = np.hstack((utils.soft_normalize(np.ones((P*Y_train.shape[1])))))\n",
    "psi_beta = lambda phi_beta: 0.5*alpha*np.linalg.norm(phi_beta - init_phi_beta, ord=2)\n",
    "psi_beta_prime = lambda phi_beta: alpha*(phi_beta - init_phi_beta)\n",
    "\n",
    "init_phi_u = utils.soft_normalize(np.ones((K)))\n",
    "psi_u      = lambda phi_u: upsilon*np.linalg.norm(phi_u, ord=1)\n",
    "psi_u_prime = lambda phi_u: upsilon*np.sign(phi_u)\n",
    "\n",
    "init_beta_scale=1e2\n",
    "psi_beta_scale = lambda beta_scale: 1e-3*(1./beta_scale)\n",
    "psi_beta_scale_prime = lambda beta_scale: -1e-3*(beta_scale**(-2))\n",
    "\n",
    "\n",
    "dmr = DistanceMatching(init_beta=init_beta,\n",
    "                       f=lambda x, y, b: functions.logistic_loss_multitask(x, y, b.T),\n",
    "                       f_prime= lambda x, y, b: functions.logistic_loss_prime_multitask(x, y, b),\n",
    "                       gamma=gamma, n_neighbors=100, calc_dist_errors_every=1,\n",
    "                       calc_closest_every=10,\n",
    "                       rho_beta=rho_beta,\n",
    "                       rho_beta_prime = rho_beta_prime,\n",
    "                       init_phi_beta = init_phi_beta,\n",
    "                       psi_beta = psi_beta,\n",
    "                       psi_beta_prime = psi_beta_prime,\n",
    "                       init_phi_u=init_phi_u,\n",
    "                       psi_u=psi_u,\n",
    "                       psi_u_prime=psi_u_prime,\n",
    "                       init_beta_scale=init_beta_scale,\n",
    "                       psi_beta_scale=psi_beta_scale,\n",
    "                       psi_beta_scale_prime=psi_beta_scale_prime,\n",
    "                       intercept=False, n_threads=0)\n",
    "\n",
    "dZ = [\n",
    "    lambda x,y: functions.safe_wrapper(x, y, functions.abs_diff)\n",
    "]\n",
    "\n",
    "for _ in range(K-1):\n",
    "    dZ.append(lambda x,y: functions.safe_wrapper(x, y, functions.abs_diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2135, 3, 6)\n"
     ]
    }
   ],
   "source": [
    "print(init_beta.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if remake_delta_Z:\n",
    "    delta_Z = dmr.make_covariate_distances(\n",
    "        Z_train, dZ, len(dZ), len(Z_train), should_normalize=True)\n",
    "    np.save(\"delta_Z.npy\", delta_Z)\n",
    "else:\n",
    "    delta_Z = np.load(\"delta_Z.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2135, 6, 2)\n"
     ]
    }
   ],
   "source": [
    "#print(vc_beta)\n",
    "#print(X_train.shape)\n",
    "#print(init_beta.shape)\n",
    "init_beta_lr = vc_beta.swapaxes(1, 2)\n",
    "init_beta_lr[:, :, -1] += np.random.uniform(0, 1, size=((init_beta_lr.shape[0], init_beta_lr.shape[1])))\n",
    "print(init_beta_lr.shape)\n",
    "\n",
    "gamma = 1e5\n",
    "lam = 1e-2\n",
    "beta_target = np.zeros_like(init_beta_lr)\n",
    "rho_beta = lambda beta, i: lam*np.sum([\n",
    "    functions.lasso_penalty(beta[:, j], beta_target[i, :, j])+\n",
    "    functions.l2_penalty(beta[:, j], beta_target[i, :, j]) for j in range(beta.shape[1])])\n",
    "rho_beta_prime = lambda beta, i: lam*(\n",
    "    functions.lasso_derivative(beta, beta_target[i])+\n",
    "    functions.l2_prime(beta, beta_target[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restart 1 of 1\n",
      "No neighborhoods supplied. Will use random neighbors.\n",
      "Iteration:1 of Max 20000. Last Iteration Took 0.000 seconds.\r"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for axis 1 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-e960dd443cc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m z_dmr_lr, b_dmr_lr = dmr_lr.fit(\n\u001b[1;32m     19\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta_U\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdelta_Z\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5e-7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     init_patience=25, verbosity=1, calc_neighbors=False, hierarchical=False)\n\u001b[0m",
      "\u001b[0;32m~/Dropbox/CMU/SAILING/Research/Distance_Matching_Regularization/Experiments/distance_matching_lowrank.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, Y, U, dU, delta_U, neighborhoods, init_lr, lr_decay, n_restarts, init_patience, max_iters, tol, verbosity, log_file, hierarchical, kd_leafsize, calc_neighbors, record_distances)\u001b[0m\n\u001b[1;32m    520\u001b[0m                         \u001b[0;34m'init_lr'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minit_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lr_decay'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlr_decay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'kd_leafsize'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkd_leafsize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m                         'neighbors': neighborhoods, 'tol': tol, 'calc_neighbors': calc_neighbors},\n\u001b[0;32m--> 522\u001b[0;31m                         {'verbosity': verbosity, 'log': log})\n\u001b[0m\u001b[1;32m    523\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Took {:.3f} seconds.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/CMU/SAILING/Research/Distance_Matching_Regularization/Experiments/distance_matching_lowrank.py\u001b[0m in \u001b[0;36m_single_restart\u001b[0;34m(self, data, opt_params, log_params)\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_update_neighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_update_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calc_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_record_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_log_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/CMU/SAILING/Research/Distance_Matching_Regularization/Experiments/distance_matching_lowrank.py\u001b[0m in \u001b[0;36m_calc_loss\u001b[0;34m(self, iteration)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_calc_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m         \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calc_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses_over_time\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/CMU/SAILING/Research/Distance_Matching_Regularization/Experiments/distance_matching_lowrank.py\u001b[0m in \u001b[0;36m_calc_losses\u001b[0;34m(self, iteration)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_beta_hat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         loss1 = np.sum([\n\u001b[0;32m--> 118\u001b[0;31m             self.f(self.X[i], self.Y[i], self.beta_hat[i]) for i in range(self.N)])\n\u001b[0m\u001b[1;32m    119\u001b[0m         loss2 = 0.5*self.gamma*np.mean(\n\u001b[1;32m    120\u001b[0m             np.mean(np.square(self.dist_errors), axis=1))\n",
      "\u001b[0;32m~/Dropbox/CMU/SAILING/Research/Distance_Matching_Regularization/Experiments/distance_matching_lowrank.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_beta_hat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         loss1 = np.sum([\n\u001b[0;32m--> 118\u001b[0;31m             self.f(self.X[i], self.Y[i], self.beta_hat[i]) for i in range(self.N)])\n\u001b[0m\u001b[1;32m    119\u001b[0m         loss2 = 0.5*self.gamma*np.mean(\n\u001b[1;32m    120\u001b[0m             np.mean(np.square(self.dist_errors), axis=1))\n",
      "\u001b[0;32m~/Dropbox/CMU/SAILING/Research/Distance_Matching_Regularization/Experiments/functions.py\u001b[0m in \u001b[0;36mlinear_loss_multitask\u001b[0;34m(x, y, beta)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlinear_loss_multitask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     return np.sum([\n\u001b[0;32m---> 25\u001b[0;31m         linear_loss(x, y[i], beta[:, i]) for i in range(len(y))])\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlinear_loss_prime_multitask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/CMU/SAILING/Research/Distance_Matching_Regularization/Experiments/functions.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlinear_loss_multitask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     return np.sum([\n\u001b[0;32m---> 25\u001b[0;31m         linear_loss(x, y[i], beta[:, i]) for i in range(len(y))])\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlinear_loss_prime_multitask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 2 is out of bounds for axis 1 with size 2"
     ]
    }
   ],
   "source": [
    "dmr_lr = DMR_LR(init_beta=init_beta_lr, #vc_beta\n",
    "                            f=functions.linear_loss_multitask,\n",
    "                            f_prime=functions.linear_loss_prime_multitask,\n",
    "                            gamma=gamma,\n",
    "                            latent_dim=2,\n",
    "                            n_neighbors=5,\n",
    "                            update_ztree_every=25,\n",
    "                            calc_dist_errors_every=1,\n",
    "                            calc_closest_every=2,\n",
    "                            rho_beta=rho_beta,\n",
    "                            rho_beta_prime = rho_beta_prime,\n",
    "                            init_phi_u=init_phi_u,\n",
    "                            psi_u=psi_u,\n",
    "                            psi_u_prime=psi_u_prime,\n",
    "                            intercept=False, log_dir=\"./\", n_threads=1)\n",
    "import sys\n",
    "sys.setrecursionlimit(100000)\n",
    "z_dmr_lr, b_dmr_lr = dmr_lr.fit(\n",
    "    X_train, Y_train, Z_train, dZ, delta_U=delta_Z, init_lr=5e-7, lr_decay=1-1e-4,\n",
    "    init_patience=25, verbosity=1, calc_neighbors=False, hierarchical=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'z_dmr_lr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-296a931ea73f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbeta_hat_dmr_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensordot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_dmr_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_dmr_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#print(dmr_lr.best_losses_over_time)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdmr_lr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_phi_u\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdmr_lr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_Z\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'z_dmr_lr' is not defined"
     ]
    }
   ],
   "source": [
    "beta_hat_dmr_lr = np.tensordot(z_dmr_lr, b_dmr_lr, axes=1)\n",
    "#print(dmr_lr.best_losses_over_time)\n",
    "print(dmr_lr.best_phi_u)\n",
    "\n",
    "print(dmr_lr.best_Z)\n",
    "np.save(\"beta_har_dmr_lr_z.npy\", dmr_lr.best_Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2135, 6)\n",
      "(2135, 3)\n",
      "(2135, 2)\n",
      "(2135, 2135, 2)\n",
      "2\n",
      "Restart 1 of 1\n",
      "No neighborhoods supplied. Will use random neighbors.\n",
      "Reached local minimum at iteration 29.ion Took 3.981 seconds.\n",
      "Took 123.229 seconds.\n",
      "** New best solution **\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(Z_train.shape)\n",
    "print(delta_Z.shape)\n",
    "print(len(dZ))\n",
    "# 4:20 on 10/8 - Experimenting with extra neighbors: Had MSE < 0.03 with Neighbors = 50.\n",
    "(beta_hat_dmr, phi_beta, phi_u, distances_over_time, losses_over_time) = dmr.fit(\n",
    "    X_train, Y_train, Z_train, dZ, delta_U=delta_Z, init_lr=1e-3, tol=1e-3, lr_decay=1-1e-7,\n",
    "    init_patience=25, verbosity=1, hierarchical=False)\n",
    "# last experiment - 10x patience. previous result was 91% of MSE of mixture.\n",
    "# Increasing to 25 mixtures seems to help mixtures without changing personalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(beta_hat_dmr, phi_beta, phi_u, distances_over_time, losses_over_time) = dmr.fit(\n",
    "    X_train, Y_train, Z_train, dZ, delta_U=delta_Z, init_lr=1e-3, tol=1e-3, lr_decay=1-1e-7,\n",
    "    init_patience=25, verbosity=1, hierarchical=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5 0.5]\n",
      "[[ 3.411e-04  4.099e-04  1.829e-04 ...  2.535e-04  2.573e-04  1.945e-04]\n",
      " [-3.087e-04 -3.742e-04 -1.719e-04 ... -2.295e-04 -2.356e-04 -2.053e-04]\n",
      " [-3.371e-04 -4.013e-04 -1.650e-04 ... -2.451e-04 -2.458e-04 -2.023e-04]\n",
      " [ 3.564e-04  4.175e-04  1.650e-04 ...  2.498e-04  2.500e-04  1.833e-04]\n",
      " [-3.299e-04 -3.860e-04 -1.618e-04 ... -2.273e-04 -2.324e-04 -2.008e-04]\n",
      " [ 2.076e-01  2.062e-01  2.169e-01 ...  2.153e-01  2.151e-01  2.166e-01]]\n",
      "[[-1.767e-04 -2.065e-04 -9.711e-05 ... -1.329e-04 -1.342e-04 -9.807e-05]\n",
      " [ 1.421e-04  1.683e-04  8.504e-05 ...  1.247e-04  1.284e-04  1.138e-04]\n",
      " [ 1.882e-04  2.063e-04  8.184e-05 ...  1.188e-04  1.189e-04  8.555e-05]\n",
      " [-1.752e-04 -2.079e-04 -8.446e-05 ... -1.241e-04 -1.242e-04 -9.305e-05]\n",
      " [ 1.452e-04  1.837e-04  7.876e-05 ...  1.200e-04  1.238e-04  1.079e-04]\n",
      " [ 3.868e-01  3.875e-01  3.822e-01 ...  3.827e-01  3.831e-01  3.823e-01]]\n",
      "(2135, 3, 6)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6QAAAAoCAYAAADpJTfjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABdpJREFUeJzt3V+IZnUdx/H3x/3jv1xqUzbbljLYm7WLCaWEIpSirBsz\nKOyivBA3aJWCbra6qKvopoKghErRpBKpRC8yaSXoqtRkyF0XaVhXct1cJMOlC3N3v12c37JP48wz\nO3OG58zM837B8JzzO79zzm+X+fCb75w/k6pCkiRJkqRJu2DoAUiSJEmSppMFqSRJkiRpEBakkiRJ\nkqRBWJBKkiRJkgZhQSpJkiRJGoQFqSRJkiRpEBMvSJPcmOS5JHNJ9k/6/NJ6kORokmeSzCZ5qrVt\nT/KHJH9vn28b6f/1lqnnknxiuJFLw0lyT5ITSQ6OtC07N0muafmbS/LDJJn0v0UawiIZ+naSY20+\nmk3yqZFtZkgakWRXkj8meTbJoSRfae3ORWNMtCBNsgn4EfBJYA/w+SR7JjkGaR25oapmquratr4f\neLyqdgOPt3Vahm4BrgZuBH7csiZNm3vpMjBqJbm5C7gd2N2+5h9T2qjuZeHv9x+0+Wimqn4HZkha\nxCnga1W1B7gO2Ney4lw0xqSvkH4AmKuqI1X1X+AB4KYJj0Far24C7mvL9wGfHml/oKper6rngTm6\nrElTpar+BPxrXvOycpPkSmBbVf25qgr4+cg+0oa2SIYWY4akearqeFU93ZZPAoeBnTgXjTXpgnQn\n8I+R9Rdbm6T/V8CBJH9Nsre17aiq4235n8COtmyupMUtNzc72/L8dmma3Znkb+2W3rO3GpohaYwk\n7wHeD/wF56KxfKmRtDZ9uKpm6G5v35fkI6Mb22/LapCRSeuUuZFW5C7gvcAMcBz43rDDkda+JG8B\nfgN8tapeG93mXPRmky5IjwG7Rtbf1dokjaiqY+3zBPAQ3S24L7dbOGifJ1p3cyUtbrm5OdaW57dL\nU6mqXq6q01V1Bvgp5x4JMUPSApJsoStGf1FVv23NzkVjTLogfRLYneSqJFvpHuJ9ZMJjkNa0JJcm\nuezsMvBx4CBdVm5t3W4FHm7LjwC3JLkwyVV0D74/MdlRS2vWsnLTbql6Lcl17Y2GXxzZR5o6Z3+I\nbm6mm4/ADElv0r7n7wYOV9X3RzY5F42xeZInq6pTSe4AHgM2AfdU1aFJjkFaB3YAD7W3e28GfllV\nv0/yJPBgktuAF4DPAVTVoSQPAs/Svd1tX1WdHmbo0nCS/Aq4Hrg8yYvAt4DvsvzcfJnubaMXA4+2\nL2nDWyRD1yeZobvF8CjwJTBD0iI+BHwBeCbJbGv7Bs5FY6W7jVmSJEmSpMnypUaSJEmSpEFYkEqS\nJEmSBmFBKkmSJEkahAWpJEmSJGkQvQrSJJ9NcijJmSRHk8wl2b9ag5MkSZIkbVx9r5AeBO5oy7vo\n/mjrnUn2jNspyd6e55WmmhmS+jFDUj9mSOrPHHV6FaRVdRh4KxDgNHAh8E7g9iV29T9f6scMSf2Y\nIakfMyT1Z45YnWdINwFngOPtE+CGVTiuJEmSJGkD27xUhyQHgHcssOmbVfXw2W7tWC8BO4HnFzjO\n/cBn2tol27K9VjZkSRdxCWZIWjkzJPVjhqT+NnqOTvLqK1V1xVL9lixIq+pjS3T5N11BegWwBXgd\neGL8SbfwwXx0qVNLkiRJktahA/XrF86n35IF6Xm4un3+B7iM7jnSty/QbzdwEcDWi9/gsSOzq3Bq\nSZIkSdJas+nK8+uXqpVfJU5yM3A/cOm8TSeratu8vns59+Du++je0CtpZS4HXhl6ENI6ZoakfsyQ\n1N9Gz9G7z+eW3V4FKUCS24CfAac4d8X11araPmafp6rq2l4nlqaYGZL6MUNSP2ZI6s8cdVbjlt2X\n6N6uexoo4A3g7lU4riRJkiRpA+tdkFbVo0muobtKuhU4Anyn73ElSZIkSRvbalwhpapmgeVcbv7J\napxXmmJmSOrHDEn9mCGpP3PEKjxDKkmSJEnSSlww9AAkSZIkSdPJglSSJEmSNAgLUkmSJEnSICxI\nJUmSJEmDsCCVJEmSJA3CglSSJEmSNAgLUkmSJEnSIP4HUj02CHBJPTMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1798243cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6QAAAAoCAYAAADpJTfjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAFPBhBQAAAAAMBVMSAEAAAAAU/F/bt24MsTDBFcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f17982795f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6QAAAAoCAYAAADpJTfjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f17983ec780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(phi_u)\n",
    "plt.matshow(np.abs(beta_hat_dmr[:, 0].T) > 1e-3)\n",
    "plt.matshow(beta_hat_dmr[:, 1].T)\n",
    "plt.matshow(beta_hat_dmr[:, 1].T - beta_hat_dmr[:, 0].T)\n",
    "print(beta_hat_dmr[:, 1].T - beta_hat_dmr[:, 0].T)\n",
    "print(beta_hat_dmr[:, 0].T)\n",
    "print(beta_hat_dmr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beta_hat_dmr_lr = np.swapaxes(beta_hat_dmr_lr, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dmr_lr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-553ff6395c2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#plt.hist(Y_test - np.mean(Y_train, axis=0))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#plt.hist(np.square(Y_test[:, :2] - np.mean(Y_train, axis=0)[:2]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mphi_u\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdmr_lr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_phi_u\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdelta_U_train_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# - np.eye(len(X_train))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dmr_lr' is not defined"
     ]
    }
   ],
   "source": [
    "#print(Y_test - np.mean(Y_train, axis=0))\n",
    "#plt.hist(Y_test - np.mean(Y_train, axis=0))\n",
    "#plt.hist(np.square(Y_test[:, :2] - np.mean(Y_train, axis=0)[:2]))\n",
    "phi_u = dmr_lr.best_phi_u\n",
    "\n",
    "delta_U_train_train = np.ones((len(X_train), len(X_train), K))# - np.eye(len(X_train))\n",
    "for i in range(len(X_train)):\n",
    "    delta_U_train_train[i, i] = np.zeros((K))\n",
    "calc_train_mse = lambda beta: calc_mse(beta, X_train, Y_train, delta_U_train_train, 1, np.ones_like(phi_u))\n",
    "\n",
    "base_train_mse, base_preds = calc_train_mse(base)\n",
    "overfit_train_mse, overfit_preds = calc_train_mse(overfit)\n",
    "mix_train_mse, mix_preds  = calc_train_mse(mixture_beta)\n",
    "vc_train_mse, vc_preds   = calc_train_mse(vc_beta)\n",
    "#dmr_train_mse  = calc_train_mse(beta_hat_dmr)\n",
    "dmr_lr_train_mse, dmr_lr_preds = calc_train_mse(beta_hat_dmr_lr)\n",
    "\n",
    "print(overfit_preds)\n",
    "print(dmr_lr_preds)\n",
    "\n",
    "print(\"===== Train MSEs =====\")\n",
    "print(\"Mean:      {:.3f}\".format(base_train_mse))\n",
    "print(\"Overfit:   {:.3f}\".format(overfit_train_mse))\n",
    "print(\"Mixture:   {:.3f}\".format(mix_train_mse))\n",
    "print(\"Vc:        {:.3f}\".format(vc_train_mse))\n",
    "#print(\"DMR:     {}\".format(dmr_train_mse))\n",
    "print(\"DMR (LR):  {:.3f}\".format(dmr_lr_train_mse))\n",
    "#print(dmr_train_mse/vc_train_mse)\n",
    "\n",
    "\n",
    "base_mse, base_preds = calc_mse(base, X_test, Y_test, delta_U_test_train, 1, np.ones_like(phi_u))\n",
    "overfit_mse, overfit_preds = calc_mse(overfit, X_test, Y_test, delta_U_test_train, 1, np.ones_like(phi_u))\n",
    "mix_mse, mix_preds = calc_mse(mixture_beta, X_test, Y_test, delta_U_test_train, 1, np.ones_like(phi_u))\n",
    "vc_mse, vc_preds = calc_mse(vc_beta, X_test, Y_test, delta_U_test_train, 1, np.ones_like(phi_u))\n",
    "#dmr_mse = calc_mse(beta_hat_dmr, X_test, Y_test, delta_U_test_train, 5, phi_u)\n",
    "dmr_lr_mse, dmr_lr_preds = calc_mse(beta_hat_dmr_lr, X_test, Y_test, delta_U_test_train, 2, phi_u)\n",
    "\n",
    "\n",
    "print(\"===== Test MSEs =====\")\n",
    "print(\"Mean:      {:.3f}\".format(base_mse))\n",
    "print(\"Overfit:   {:.3f}\".format(overfit_mse))\n",
    "print(\"Mixture:   {:.3f}\".format(mix_mse))\n",
    "print(\"Vc:        {:.3f}\".format(vc_mse))\n",
    "#print(\"DMR:     {}\".format(dmr_mse))\n",
    "print(\"DMR (LR):  {:.3f}\".format(dmr_lr_mse))\n",
    "#print(dmr_mse/vc_mse)\n",
    "\n",
    "calc_mae = lambda a,b,c,d,e,f: calc_test_err(a,b,c,d,e,f,mse=False, mae=True)\n",
    "calc_test_mae = lambda theta, n, phi: calc_mae(theta, X_test, Y_test, delta_U_test_train, n, phi)\n",
    "\n",
    "base_mae, base_preds = calc_test_mae(base, 1, np.ones_like(phi_u))\n",
    "overfit_mae, base_preds = calc_test_mae(overfit, 1, np.ones_like(phi_u))\n",
    "mix_mae, base_preds = calc_test_mae(mixture_beta, 1, np.ones_like(phi_u))\n",
    "vc_mae, base_preds = calc_test_mae(vc_beta, 1, np.ones_like(phi_u))\n",
    "#dmr_mae = calc_mae(beta_hat_dmr, X_test, Y_test, delta_U_test_train, 5, phi_u)\n",
    "dmr_lr_mae, base_preds = calc_test_mae(beta_hat_dmr_lr, 2, phi_u)\n",
    "print(\"\\n==== Test MAEs =====\")\n",
    "print(\"Mean:     {:.3f}\".format(base_mae))\n",
    "print(\"Overfit:  {:.3f}\".format(overfit_mae))\n",
    "print(\"Mixture:  {:.3f}\".format(mix_mae))\n",
    "print(\"VC:       {:.3f}\".format(vc_mae))\n",
    "#print(\"DMR:      {}\".format(dmr_mae))\n",
    "print(\"DMR (LR): {:.3f}\".format(dmr_lr_mae))\n",
    "#print(dmr_mae/mix_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'phi_beta' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-b4b8ab716f8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta_hat_dmr_lr.npy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta_hat_dmr_lr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"phi_u.npy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphi_u\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"phi_beta.npy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphi_beta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta_hat_vc.npy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvc_beta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'phi_beta' is not defined"
     ]
    }
   ],
   "source": [
    "# Sort and display MSE by increasing NN Dist \n",
    "np.save(\"beta_hat_dmr_lr.npy\", beta_hat_dmr_lr)\n",
    "np.save(\"phi_u.npy\", phi_u)\n",
    "np.save(\"phi_beta.npy\", phi_beta)\n",
    "np.save(\"beta_hat_vc.npy\", vc_beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beta_hat_dmr_lr = np.load(\"beta_hat_dmr_lr.npy\")\n",
    "phi_u = np.load(\"phi_u.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 3, 6)\n"
     ]
    }
   ],
   "source": [
    "#print(np.argsort(np.abs((Z_test[0] - Z_train).dot(phi_u))))\n",
    "\n",
    "beta_hat_dmr_test = np.array([\n",
    "    np.mean(beta_hat_dmr_lr[np.argsort(np.abs((Z_test[i] - Z_train).dot(phi_u)))[:3]], axis=0)\n",
    "    for i in range(len(X_test))])\n",
    "print(beta_hat_dmr_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dmr_preds_train = np.array([\n",
    "    X_train[i].dot(beta_hat_dmr_lr[i].T) for i in range(len(X_train))\n",
    "])\n",
    "dmr_preds_test = np.array([\n",
    "    X_test[i].dot(beta_hat_dmr_test[i].T) for i in range(len(X_test))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.929 1.066 0.98 ]\n",
      " [1.038 0.96  0.987]\n",
      " [0.795 1.17  0.961]\n",
      " ...\n",
      " [0.805 1.163 1.077]\n",
      " [0.867 1.117 1.064]\n",
      " [0.893 1.097 1.039]]\n",
      "[[0.86  1.123 1.021]\n",
      " [0.896 1.094 1.061]\n",
      " [0.965 1.034 1.024]\n",
      " ...\n",
      " [0.903 1.089 1.04 ]\n",
      " [0.946 1.051 0.983]\n",
      " [0.933 1.063 1.049]]\n"
     ]
    }
   ],
   "source": [
    "dmr_preds_train = np.exp(dmr_preds_train / (1+dmr_preds_train))\n",
    "dmr_preds_test = np.exp(dmr_preds_test / (1+dmr_preds_test))\n",
    "print(dmr_preds_train)\n",
    "print(dmr_preds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2988295281789244 0.21521032376581592 0.25701992597237017\n",
      "0.2730785224011241\n",
      "-13.193309451765138\n"
     ]
    }
   ],
   "source": [
    "a = mean_squared_error(Y_train[:, 0], dmr_preds_train[:, 0])\n",
    "b = mean_squared_error(Y_train[:, 1], dmr_preds_train[:, 1])\n",
    "print(a, b, (a+b)/2)\n",
    "\n",
    "a = mean_squared_error(Y_test[:, 0], dmr_preds_test[:, 0])\n",
    "b = mean_squared_error(Y_test[:, 1], dmr_preds_test[:, 1])\n",
    "print((a+b)/2)\n",
    "\n",
    "a = r2_score(Y_test[:, 0], dmr_preds_test[:, 0])\n",
    "b = r2_score(Y_test[:, 1], dmr_preds_test[:, 1])\n",
    "print((a+b)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2135, 3, 6)\n",
      "Making Co-Variate Distance Matrix of Size 712x712x11\n",
      "627\t/712\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-58e0ff34a3ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta_hat_dmr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m delta_Z_test = dmr.make_covariate_distances(\n\u001b[0;32m----> 7\u001b[0;31m         Z_test, dZ, len(dZ), len(Z_test), should_normalize=False)\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mN_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta_Z_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mdelta_Z_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdelta_Z_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphi_u\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/CMU/SAILING/Research/Distance_Matching_Regularization/Experiments/distance_matching_functional.py\u001b[0m in \u001b[0;36mmake_covariate_distances\u001b[0;34m(self, U, dU, K, N, should_normalize)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{}\\t/{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_dist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/CMU/SAILING/Research/Distance_Matching_Regularization/Experiments/distance_matching_functional.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/CMU/SAILING/Research/Distance_Matching_Regularization/Experiments/distance_matching_functional.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(j)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{}\\t/{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_dist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/CMU/SAILING/Research/Distance_Matching_Regularization/Experiments/distance_matching_functional.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i, j)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;31m#with concurrent.futures.ThreadPoolExecutor(max_workers=self.n_threads) as executor:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         get_dist = lambda i, j: np.array([\n\u001b[0;32m---> 85\u001b[0;31m             dU[k](U[i, k], U[j, k]) for k in range(K)], dtype=\"float32\")\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{}\\t/{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/CMU/SAILING/Research/Distance_Matching_Regularization/Experiments/distance_matching_functional.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;31m#with concurrent.futures.ThreadPoolExecutor(max_workers=self.n_threads) as executor:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         get_dist = lambda i, j: np.array([\n\u001b[0;32m---> 85\u001b[0;31m             dU[k](U[i, k], U[j, k]) for k in range(K)], dtype=\"float32\")\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{}\\t/{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-0b7d8012633c>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0mdZ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msafe_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs_diff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Dropbox/CMU/SAILING/Research/Distance_Matching_Regularization/Experiments/functions.py\u001b[0m in \u001b[0;36msafe_wrapper\u001b[0;34m(x, y, f)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m#print(\"Trying {}\".format(f))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Dropbox/CMU/SAILING/Research/Distance_Matching_Regularization/Experiments/functions.py\u001b[0m in \u001b[0;36mabs_diff\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mabs_diff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdiscrete_diff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with open(\"results.txt\", 'w') as result_file:\n",
    "    print(\"{}\\n\".format(dmr_mse), file=result_file)\n",
    "    print(\"{}\\n\".format(vc_mse), file=result_file)\n",
    "\n",
    "print(beta_hat_dmr.shape)\n",
    "delta_Z_test = dmr.make_covariate_distances(\n",
    "        Z_test, dZ, len(dZ), len(Z_test), should_normalize=False)\n",
    "N_test = len(delta_Z_test)\n",
    "delta_Z_test = np.array([np.array([delta_Z_test[i, j].dot(phi_u) for j in range(N_test)]) for i in range(N_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0.      973.226  1683.586 ...  1177.297  1097.142 46845.354]\n",
      " [  973.226     0.     1926.495 ...   419.673   355.443 47260.973]\n",
      " [ 1683.586  1926.495     0.    ...  2331.287  1957.861 45467.598]\n",
      " ...\n",
      " [ 1177.297   419.673  2331.287 ...     0.      609.816 47587.732]\n",
      " [ 1097.142   355.443  1957.861 ...   609.816     0.    47119.617]\n",
      " [46845.354 47260.973 45467.598 ... 47587.732 47119.617     0.   ]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "nearest_neighbor_dists = np.amin(delta_Z_test, axis=0)\n",
    "print(delta_Z_test)\n",
    "print(nearest_neighbor_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  0.,   0.,   0.,   0.,   0., 712.,   0.,   0.,   0.,   0.]),\n",
       " array([-0.5, -0.4, -0.3, -0.2, -0.1,  0. ,  0.1,  0.2,  0.3,  0.4,  0.5]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAENhJREFUeJzt3X+sX3ddx/HnyxaGAZGNXa+1rbYmN5guMsDrghkoY+DG\nj9CZmKVEsDFNKqEiJCTYaoJ/mCbjH4ImjqQCeglIrfxwDSBYCsQYAuNuTKAtdZXRtE1/XCbID5OR\nlrd/3DP9rqz9nm/v93vv+tnzkTTncz7n87nn/UnT1z333O85TVUhSWrXT610AZKkyTLoJalxBr0k\nNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY1bvdIFAFx//fW1YcOGlS5Dkq4q991337eramrY\nuCdE0G/YsIH5+fmVLkOSripJjvcZ560bSWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BL\nUuMMeklq3NAnY5M8B/iHga5fBt4OvL/r3wB8C7izqr7TzdkFbAMuAH9cVZ8ea9XSMtqw8xMrct5v\n3fWqFTmv2jP0ir6qjlbV86rqecCvAf8DfAzYCRysqhngYLdPkk3AFuAG4Hbg7iSrJlS/JGmIUW/d\n3Ar8Z1UdBzYDc13/HHBH194M7K2qR6rqIeAYcNM4ipUkjW7UoN8CfKhrT1fV6a59Bpju2muBEwNz\nTnZ9j5Fke5L5JPMLCwsjliFJ6qt30Cd5KvAa4B8vPlZVBdQoJ66qPVU1W1WzU1ND37IpSbpCo1zR\nvwK4v6rOdvtnk6wB6Lbnuv5TwPqBeeu6PknSChgl6F/L/9+2AdgPbO3aW4F7Bvq3JLkmyUZgBrh3\nqYVKkq5Mr/94JMnTgZcDfzjQfRewL8k24DhwJ0BVHUqyDzgMnAd2VNWFsVYtSeqtV9BX1Q+BZ1/U\n9zCLn8J5vPG7gd1Lrk6StGQ+GStJjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEv\nSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMb1Cvok\nz0ry4STfSHIkyW8kuS7JgSQPdttrB8bvSnIsydEkt02ufEnSMH2v6P8S+FRV/QpwI3AE2AkcrKoZ\n4GC3T5JNwBbgBuB24O4kq8ZduCSpn6FBn+Rngd8E3gtQVT+qqu8Cm4G5btgccEfX3gzsrapHquoh\n4Bhw07gLlyT10+eKfiOwAPxtkq8keU+SpwPTVXW6G3MGmO7aa4ETA/NPdn2PkWR7kvkk8wsLC1e+\nAknSZfUJ+tXAC4B3V9XzgR/S3aZ5VFUVUKOcuKr2VNVsVc1OTU2NMlWSNII+QX8SOFlVX+r2P8xi\n8J9Nsgag257rjp8C1g/MX9f1SZJWwNCgr6ozwIkkz+m6bgUOA/uBrV3fVuCerr0f2JLkmiQbgRng\n3rFWLUnqbXXPcW8CPpjkqcA3gT9g8ZvEviTbgOPAnQBVdSjJPha/GZwHdlTVhbFXLknqpVfQV9UD\nwOzjHLr1EuN3A7uXUJckaUx8MlaSGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINe\nkhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY3rFfRJ\nvpXka0keSDLf9V2X5ECSB7vttQPjdyU5luRoktsmVbwkabhRruhvqarnVdVst78TOFhVM8DBbp8k\nm4AtwA3A7cDdSVaNsWZJ0giWcutmMzDXteeAOwb691bVI1X1EHAMuGkJ55EkLUHfoC/gM0nuS7K9\n65uuqtNd+www3bXXAicG5p7s+h4jyfYk80nmFxYWrqB0SVIfq3uOe1FVnUryc8CBJN8YPFhVlaRG\nOXFV7QH2AMzOzo40V5LUX68r+qo61W3PAR9j8VbM2SRrALrtuW74KWD9wPR1XZ8kaQUMDfokT0/y\nM4+2gd8Gvg7sB7Z2w7YC93Tt/cCWJNck2QjMAPeOu3BJUj99bt1MAx9L8uj4v6+qTyX5MrAvyTbg\nOHAnQFUdSrIPOAycB3ZU1YWJVC9JGmpo0FfVN4EbH6f/YeDWS8zZDexecnWSpCXzyVhJapxBL0mN\nM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiD\nXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDWud9AnWZXkK0k+3u1fl+RAkge77bUDY3clOZbkaJLb\nJlG4JKmfUa7o3wwcGdjfCRysqhngYLdPkk3AFuAG4Hbg7iSrxlOuJGlUvYI+yTrgVcB7Bro3A3Nd\new64Y6B/b1U9UlUPAceAm8ZTriRpVH2v6N8FvA348UDfdFWd7tpngOmuvRY4MTDuZNf3GEm2J5lP\nMr+wsDBa1ZKk3oYGfZJXA+eq6r5LjamqAmqUE1fVnqqararZqampUaZKkkawuseYm4HXJHkl8DTg\nmUk+AJxNsqaqTidZA5zrxp8C1g/MX9f1SZJWwNAr+qraVVXrqmoDi79k/WxVvQ7YD2zthm0F7una\n+4EtSa5JshGYAe4de+WSpF76XNFfyl3AviTbgOPAnQBVdSjJPuAwcB7YUVUXllypJOmKjBT0VfV5\n4PNd+2Hg1kuM2w3sXmJtkqQx8MlYSWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMM\neklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1bmjQ\nJ3laknuT/HuSI0nu6vqvS3IgyYPd9tqBObuSHEtyNMltk1yAJOny+lzRPwK8tKpuBJ4L3JLkxcBO\n4GBVzQAHu32SbAK2ADcAtwN3J1k1ieIlScMNDfpa9INu9ynAKuA7wGZgruufA+7o2puBvVX1SFU9\nBBwDbhpr1ZKk3nrdo0+yKskDwDng81X1dWC6qk53Q84A0117LXBiYPrJrk+StAJ6BX1VXaiq5wHr\ngBcnueWi4wXUKCdOsj3JfJL5hYWFUaZKkkYw0qduquq7wCeAWeBskjUA3fZcN+wUsH5g2rqu7+Kv\ntaeqZqtqdmpq6kpqlyT10OdTN1NJntW1fxp4OfAAsB/Y2g3bCtzTtfcDW5Jck2QjMAPcO+7CJUn9\nrO4xZg0wl+SnWPzG8IGqOpDkfmBfkm3AceBOgKo6lGQfcBg4D+yoqguTKV+SNMzQoK+qrwLPf5z+\nh4FbLzFnN7B7ydVJkpbMJ2MlqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalx\nBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktS4oUGfZH2S\nzyU5nORQkjd3/dclOZDkwW577cCcXUmOJTma5LZJLkCSdHl9rujPA2+tqk3AC4EdSTYBO4GDVTUD\nHOz26Y5tAW4AbgfuTrJqEsVLkoYbGvRVdbqq7u/a3weOAGuBzcBcN2wOuKNrbwb2VtUjVfUQcAy4\nadyFS5L6GekefZINwPOBLwHTVXW6O3QGmO7aa4ETA9NOdn2SpBXQO+iTPAP4CPCWqvre4LGqKqBG\nOXGS7Unmk8wvLCyMMlWSNIJeQZ/kKSyG/Aer6qNd99kka7rja4BzXf8pYP3A9HVd32NU1Z6qmq2q\n2ampqSutX5I0RJ9P3QR4L3Ckqt45cGg/sLVrbwXuGejfkuSaJBuBGeDe8ZUsSRrF6h5jbgZeD3wt\nyQNd358CdwH7kmwDjgN3AlTVoST7gMMsfmJnR1VdGHvlkqRehgZ9Vf0bkEscvvUSc3YDu5dQlyRp\nTHwyVpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mN\nM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjRsa9Enel+Rckq8P9F2X5ECSB7vt\ntQPHdiU5luRoktsmVbgkqZ8+V/R/B9x+Ud9O4GBVzQAHu32SbAK2ADd0c+5Osmps1UqSRjY06Kvq\nX4H/uqh7MzDXteeAOwb691bVI1X1EHAMuGlMtUqSrsCV3qOfrqrTXfsMMN211wInBsad7PokSStk\nyb+MraoCatR5SbYnmU8yv7CwsNQyJEmXcKVBfzbJGoBue67rPwWsHxi3ruv7CVW1p6pmq2p2amrq\nCsuQJA1zpUG/H9jatbcC9wz0b0lyTZKNwAxw79JKlCQtxephA5J8CHgJcH2Sk8CfA3cB+5JsA44D\ndwJU1aEk+4DDwHlgR1VdmFDtkqQehgZ9Vb32EoduvcT43cDupRQlSRofn4yVpMYZ9JLUOINekhpn\n0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9\nJDXOoJekxhn0ktQ4g16SGmfQS1LjJhb0SW5PcjTJsSQ7J3UeSdLlTSTok6wC/hp4BbAJeG2STZM4\nlyTp8iZ1RX8TcKyqvllVPwL2ApsndC5J0mVMKujXAicG9k92fZKkZbZ6pU6cZDuwvdv9QZKjK1XL\nElwPfHuli1hmrnmZ5B3LfcbHeLL9PV+t6/2lPoMmFfSngPUD++u6vv9TVXuAPRM6/7JIMl9Vsytd\nx3JyzU8OT7Y1t77eSd26+TIwk2RjkqcCW4D9EzqXJOkyJnJFX1Xnk/wR8GlgFfC+qjo0iXNJki5v\nYvfoq+qTwCcn9fWfIK7qW09XyDU/OTzZ1tz0elNVK12DJGmCfAWCJDXOoB9BkuuSHEjyYLe99jJj\nVyX5SpKPL2eN49ZnzUnWJ/lcksNJDiV580rUuhTDXtmRRX/VHf9qkhesRJ3j1GPNv9et9WtJvpDk\nxpWoc5z6vpolya8nOZ/kd5ezvkkx6EezEzhYVTPAwW7/Ut4MHFmWqiarz5rPA2+tqk3AC4EdV9Mr\nL3q+suMVwEz3Zzvw7mUtcsx6rvkh4Leq6leBv+Aqv4/d99Us3bh3AP+yvBVOjkE/ms3AXNeeA+54\nvEFJ1gGvAt6zTHVN0tA1V9Xpqrq/a3+fxW9wV9OT0H1e2bEZeH8t+iLwrCRrlrvQMRq65qr6QlV9\np9v9IovPw1zN+r6a5U3AR4Bzy1ncJBn0o5muqtNd+wwwfYlx7wLeBvx4WaqarL5rBiDJBuD5wJcm\nW9ZY9XllR2uv9Rh1PduAf55oRZM3dM1J1gK/w1X+E9vFVuwVCE9UST4D/PzjHPqzwZ2qqiQ/8ZGl\nJK8GzlXVfUleMpkqx2upax74Os9g8UroLVX1vfFWqZWS5BYWg/5FK13LMngX8CdV9eMkK13L2Bj0\nF6mql13qWJKzSdZU1enux/bH+9HuZuA1SV4JPA14ZpIPVNXrJlTyko1hzSR5Cosh/8Gq+uiESp2U\noa/s6DnmatJrPUmey+ItyFdU1cPLVNuk9FnzLLC3C/nrgVcmOV9V/7Q8JU6Gt25Gsx/Y2rW3Avdc\nPKCqdlXVuqrawOKrHz77RA75HoauOYv/Kt4LHKmqdy5jbePS55Ud+4Hf7z5980LgvwduaV2Nhq45\nyS8CHwVeX1X/sQI1jtvQNVfVxqra0P37/TDwxqs95MGgH9VdwMuTPAi8rNsnyS8kafUp4D5rvhl4\nPfDSJA90f165MuWOrqrOA4++suMIsK+qDiV5Q5I3dMM+CXwTOAb8DfDGFSl2THqu+e3As4G7u7/T\n+RUqdyx6rrlJPhkrSY3zil6SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUuP8FNYjO\nkQgXL+IAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f73733f8d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(nearest_neighbor_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.091 0.091 0.091 0.091 0.091 0.091 0.091 0.091 0.091 0.091 0.091]\n"
     ]
    }
   ],
   "source": [
    "print(phi_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.016 0.016 0.016 0.016 0.016 0.016 0.016 0.016 0.016 0.016 0.016 0.016\n",
      " 0.016 0.016 0.016 0.016 0.016 0.016 0.016 0.016 0.016 0.016 0.016 0.016\n",
      " 0.016 0.016 0.016 0.016 0.016 0.016 0.016 0.016 0.016 0.016 0.016 0.016\n",
      " 0.016 0.016 0.016 0.016 0.016 0.016 0.016 0.016 0.016 0.016 0.016 0.016\n",
      " 0.016 0.016 0.016 0.016 0.016 0.016 0.016 0.016 0.016 0.016 0.016 0.016\n",
      " 0.016 0.016 0.016]\n"
     ]
    }
   ],
   "source": [
    "print(phi_beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
