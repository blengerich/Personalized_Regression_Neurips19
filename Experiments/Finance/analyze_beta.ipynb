{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "from distance_matching_lowrank import DistanceMatching as DistanceMatchingLR\n",
    "from distance_matching_functional_bkp import DistanceMatching\n",
    "import functions\n",
    "import utils\n",
    "import datetime\n",
    "sys.path.append(\"../baselines/\")\n",
    "from baselines import baselines\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "mse = mean_squared_error\n",
    "\n",
    "try:\n",
    "    from sklearn.manifold import TSNE\n",
    "except Error:\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "    warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")\n",
    "    from sklearn.manifold import TSNE\n",
    "\n",
    "\n",
    "# Finished experiment with splitting by date - baselines terrible, personalized ok!\n",
    "# TODO: Improve data generation process to only have price movement.\n",
    "resplit_data = False\n",
    "remake_delta_Z = resplit_data\n",
    "remake_dz_test_train = resplit_data\n",
    "\n",
    "refit_lr = resplit_data\n",
    "refit_mixture = resplit_data\n",
    "refit_vc = resplit_data\n",
    "\n",
    "should_plot = True\n",
    "if should_plot:\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "npz_ar = np.load(\"train_test_split.npz\")\n",
    "X_train = npz_ar[\"arr_0\"]\n",
    "X_test = npz_ar[\"arr_1\"]\n",
    "Y_train = npz_ar[\"arr_2\"]\n",
    "Y_test = npz_ar[\"arr_3\"]\n",
    "Z_train = npz_ar[\"arr_4\"]\n",
    "Z_test = npz_ar[\"arr_5\"]\n",
    "train_idx = npz_ar[\"arr_6\"]\n",
    "test_idx = npz_ar[\"arr_7\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beta_hat_dmr = np.load(\"beta_hat_dmr_lr.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{383, 513, 898, 520, 524, 657, 147, 533, 918, 791, 23, 281, 796, 286, 927, 417, 418, 555, 45, 305, 689, 819, 179, 694, 184, 825, 963, 453, 839, 329, 203, 77, 207, 737, 611, 227, 101, 485, 359, 1000, 996, 995, 249, 1019, 635, 125, 893, 510}\n"
     ]
    }
   ],
   "source": [
    "print(set(np.argmax(beta_hat_dmr, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "securities = ['VOO', 'SPY', 'YINN', 'XIV', 'IEO', 'CHIX', 'YANG', 'RDS-A', 'OA', 'BRK-B', 'TSLA', 'JPM', 'AAPL', 'HSBC', 'GOOGL', 'NVDA', 'E', 'BP', 'WMT', 'AMZN', 'LMT', 'MU', 'SNP', 'GM', 'FB', 'GOOG']\n",
    "print(len(securities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "fo = lambda x: str(datetime.datetime.fromordinal(x))[:-9]\n",
    "    \n",
    "def plot_models_over_time(security):\n",
    "    mu_idx = np.where(Z_train[:, 0] == security)[0]\n",
    "    #fig = plt.figure(figsize=(6,6))\n",
    "    fig = plt.figure()\n",
    "    ax = plt.gca()\n",
    "    handle = ax.matshow(beta_hat_dmr[mu_idx, :], cmap=\"RdBu\")\n",
    "    y_ticks = ax.get_yticks()\n",
    "    \n",
    "    times = [Z_train[int(mu_idx[int(x)]), -1] for x in y_ticks[1:-1]]\n",
    "    ticks = ['']\n",
    "    ticks.extend(list(map(fo, list(map(int, times)))))\n",
    "    ticks.append('')\n",
    "    for i in range(1, len(ticks)-1):\n",
    "        if len(ticks[i-1]) > 4:\n",
    "            #try:\n",
    "            if int(ticks[i][:4])*100 + int(ticks[i][5:7]) < int(ticks[i-1][:4])*100 + int(ticks[i-1][5:7]) + 100:\n",
    "                #if int(ticks[i][5:7]) < :\n",
    "                ticks[i] = ''\n",
    "            #except ValueError:\n",
    "            #    continue\n",
    "    ax.set_yticklabels(ticks)\n",
    "    cbar = fig.colorbar(handle)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"results/figures/models_over_time/models_over_time_{}.pdf\".format(security), dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "for security in securities:\n",
    "    plot_models_over_time(security)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.max_open_warning'] = 30\n",
    "def feat_name(x):\n",
    "    if x >= 52:\n",
    "        return (\"News\", x - 52)\n",
    "    security = securities[int(x / 2)]\n",
    "    if x % 2 == 0:\n",
    "        return (security, \"Price\")\n",
    "    else:\n",
    "        return (security, \"Vol.\")\n",
    "\n",
    "import pandas\n",
    "from collections import Counter    \n",
    "\n",
    "for security in securities:\n",
    "    #print(security)\n",
    "    my_idx = Z_train[:, 0] == security\n",
    "    my_beta = beta_hat_dmr[my_idx]\n",
    "    my_features = [np.argmax(x) for x in my_beta]\n",
    "    my_feature_names = [feat_name(x % 102) for x in list(my_features)]\n",
    "    #print(my_feature_names)\n",
    "    letter_counts = Counter(my_feature_names)\n",
    "    #fig = plt.figure(figsize=(8,8))\n",
    "    df = pandas.DataFrame.from_dict(letter_counts, orient='index')\n",
    "    df.plot(kind='bar', legend=False)\n",
    "    plt.xlabel(\"Most Predictive Feature\", fontsize=18)\n",
    "    plt.ylabel(\"Number of Samples\", fontsize=18)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"results/features_hist_{}.pdf\".format(security), dpi=300)\n",
    "    plt.close()\n",
    "    #plt.title(security)\n",
    "    \n",
    "    \n",
    "    #my_features = reversed(np.argsort(np.sum(np.abs(my_beta), axis=0)))\n",
    "    #print(security, my_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import umap.umap_ as umap\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Indexed 12735 samples in 0.536s...\n",
      "[t-SNE] Computed neighbors for 12735 samples in 133.543s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 12735\n",
      "[t-SNE] Computed conditional probabilities for sample 2000 / 12735\n",
      "[t-SNE] Computed conditional probabilities for sample 3000 / 12735\n",
      "[t-SNE] Computed conditional probabilities for sample 4000 / 12735\n",
      "[t-SNE] Computed conditional probabilities for sample 5000 / 12735\n",
      "[t-SNE] Computed conditional probabilities for sample 6000 / 12735\n",
      "[t-SNE] Computed conditional probabilities for sample 7000 / 12735\n",
      "[t-SNE] Computed conditional probabilities for sample 8000 / 12735\n",
      "[t-SNE] Computed conditional probabilities for sample 9000 / 12735\n",
      "[t-SNE] Computed conditional probabilities for sample 10000 / 12735\n",
      "[t-SNE] Computed conditional probabilities for sample 11000 / 12735\n",
      "[t-SNE] Computed conditional probabilities for sample 12000 / 12735\n",
      "[t-SNE] Computed conditional probabilities for sample 12735 / 12735\n",
      "[t-SNE] Mean sigma: 0.000721\n"
     ]
    },
    {
     "ename": "PendingDeprecationWarning",
     "evalue": "the matrix subclass is not the recommended way to represent matrices or deal with linear algebra (see https://docs.scipy.org/doc/numpy/user/numpy-for-matlab-users.html). Please adjust your code to use regular ndarray.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPendingDeprecationWarning\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-12aa17e57e96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m750\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#u = umap.UMAP()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbeta_hat_small\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta_hat_dmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/sklearn/manifold/t_sne.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    892\u001b[0m             \u001b[0mEmbedding\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlow\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdimensional\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m         \"\"\"\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/sklearn/manifold/t_sne.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, skip_num_points)\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# compute the joint probability distribution for the input space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             P = _joint_probabilities_nn(distances_nn, neighbors_nn,\n\u001b[0;32m--> 780\u001b[0;31m                                         self.perplexity, self.verbose)\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/sklearn/manifold/t_sne.py\u001b[0m in \u001b[0;36m_joint_probabilities_nn\u001b[0;34m(distances, neighbors, desired_perplexity, verbose)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;31m# Normalize the joint probability distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0msum_P\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMACHINE_EPSILON\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m     \u001b[0mP\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0msum_P\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(self, axis, dtype, out)\u001b[0m\n\u001b[1;32m    604\u001b[0m         \u001b[0;31m# is in {None, -1, 0, 1}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mspmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0msum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(self, axis, dtype, out)\u001b[0m\n\u001b[1;32m   1002\u001b[0m             \u001b[0;31m# sum over rows and columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m             return (self * np.asmatrix(np.ones(\n\u001b[0;32m-> 1004\u001b[0;31m                 (n, 1), dtype=res_dtype))).sum(\n\u001b[0m\u001b[1;32m   1005\u001b[0m                 dtype=dtype, out=out)\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/numpy/matrixlib/defmatrix.py\u001b[0m in \u001b[0;36masmatrix\u001b[0;34m(data, dtype)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \"\"\"\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/numpy/matrixlib/defmatrix.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(subtype, data, dtype, copy)\u001b[0m\n\u001b[1;32m    116\u001b[0m                       \u001b[0;34m'numpy-for-matlab-users.html). '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                       \u001b[0;34m'Please adjust your code to use regular ndarray.'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m                       PendingDeprecationWarning, stacklevel=2)\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mdtype2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPendingDeprecationWarning\u001b[0m: the matrix subclass is not the recommended way to represent matrices or deal with linear algebra (see https://docs.scipy.org/doc/numpy/user/numpy-for-matlab-users.html). Please adjust your code to use regular ndarray."
     ]
    }
   ],
   "source": [
    "t = TSNE(n_iter=750, verbose=1)\n",
    "#u = umap.UMAP()\n",
    "beta_hat_small = t.fit_transform(beta_hat_dmr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
